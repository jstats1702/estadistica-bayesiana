---
title: "Comparación de modelos"
author: 
- Juan Sosa PhD
- Email   jcsosam@unal.edu.co
- GitHub  https://github.com/jstats1702 
date: ""
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Intoducción

Las medidas de **precisión predictiva** se denominan **criterios de información** y se definen en función de la **devianza** (*deviance*):
$$-2\,\text{log}\,p(\boldsymbol{y}\mid\hat{\boldsymbol{\theta}})\,.$$

El factor $-2$ se utiliza para emular el estadístico asociado con la **prueba de razón de verosimilitud** (*Likelihood-ratio test*):
$$
\lambda = -2\,\frac{\text{sup}_{\theta\in\Theta_0} L(\theta)}{\text{sup}_{\theta\in\Theta} L(\theta)}
$$
donde $L(\cdot)$ es la función de verosimilitud.

No se debe elegir necesariamente el modelo con la devianza más baja. Es necesario **hacer una corrección** de cuánto aumentará la **precisión predictiva** (ajuste del modelo) teniendo en cuenta el **número de parámetros**.

# Criterios de información

Hay disponibles varios **métodos para estimar la precisión predictiva** sin utilizar datos fuera de la muestra.

El **Criterio de Información de la Devianza** (DIC, *Deviance Information Criterion*) es una versión Bayesiana del **Criterio de Información de Akaike** (AIC, *Akaike Infomation Criterion*, $\text{AIC}=-2\,\text{log}\,p(\boldsymbol{y}\mid\hat{\boldsymbol{\theta}}_{\text{MLE}})+2k$, donde $k$ es el número de parámetros del modelo):
$$
\text{DIC} = -2\,\text{log}\,p(\boldsymbol{y}\mid\hat{\boldsymbol{\theta}}_{\text{Bayes}}) + 2p_{\text{DIC}}
$$
donde 
$$
\hat{\boldsymbol{\theta}}_{\text{Bayes}} = \textsf{E}(\boldsymbol{\theta}\mid\boldsymbol{y})\approx\frac{1}{B}\sum_{b=1}^B \boldsymbol{\theta}^{(b)}
$$
es la media posterior de $\boldsymbol{\theta}$ y 
$$
p_{\text{DIC}} = 2\left( \text{log}\,p(\boldsymbol{y}\mid\hat{\boldsymbol{\theta}}_{\text{Bayes}}) - \textsf{E}( \text{log}\,p(\boldsymbol{y}\mid\boldsymbol{\theta})  \mid \boldsymbol{y} ) \right) \approx 2\left( \text{log}\,p(\boldsymbol{y}\mid\hat{\boldsymbol{\theta}}_{\text{Bayes}}) - \frac{1}{B}\sum_{b=1}^B \text{log}\,p\left(\boldsymbol{y}\mid \boldsymbol{\theta}^{(b)}\right)  \right)
$$
es el **número efectivo de parámetros**.

- ***Spiegelhalter, D. J., Best, N. G., Carlin, B. P., & Van Der Linde, A. (2002). Bayesian measures of model complexity and fit. Journal of the royal statistical society: Series b (statistical methodology), 64(4), 583-639.***
- ***Spiegelhalter, D. J., Best, N. G., Carlin, B. P., & Van der Linde, A. (2014). The deviance information criterion: 12 years on. Journal of the Royal Statistical Society: Series B: Statistical Methodology, 485-493.***

Similarmente, el **Crtireio de Información de Watanabe-Akaike** (WAIC, *Watanabe-Akaike Information Criterion*) se define como:
$$
\text{WAIC} = -2\text{lppd} + 2p_{\text{WAIC}}
$$
donde
$$
\text{lppd} = \text{log}\prod_{i=1}^n p(y_i\mid\boldsymbol{y}) = \sum_{i=1}^n\text{log}\int_\Theta p (y_i\mid\boldsymbol{\theta})p(\boldsymbol{\theta}\mid\boldsymbol{y})\,\text{d}\boldsymbol{\theta} \approx \sum_{i=1}^n\text{log}\left(\frac{1}{B}\sum_{b=1}^B p\left(y_i\mid\boldsymbol{\theta^{(b)}}\right)\right)
$$
es la **densidad predictiva puntual logarítmica** (lppd, *log posterior predictive density*, como la devianza cuantifica la precisión predictiva del modelo), y
$$
p_{\text{WAIC}} = 2\sum_{i=1}^n\left( \text{log}\,\textsf{E}(p(y_i\mid\boldsymbol{\theta})\mid\boldsymbol{y}) - \textsf{E}(\text{log}\,p(y_i\mid\boldsymbol{\theta})\mid\boldsymbol{y}) \right) \approx 
2\sum_{i=1}^n\left(\text{log}\left( \frac{1}{B}\sum_{b=1}^B p\left(y_i\mid\boldsymbol{\theta}^{(b)}\right) \right) - \frac{1}{B}\sum_{b=1}^B \text{log}\,p\left(y_i\mid \boldsymbol{\theta}^{(b)} \right)\right) 
$$
es el **número efectivo de parámetros**.

- ***Watanabe, S., & Opper, M. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory. Journal of machine learning research, 11(12).***
- ***Gelman, A., Hwang, J., & Vehtari, A. (2014). Understanding predictive information criteria for Bayesian models. Statistics and computing, 24(6), 997-1016.***

El WAIC es un enfoque completamente Bayesiano para estimar la precisión predictiva fuera de la muestra.

También existe el llamado **Criterio de Información Bayesiano** (BIC, *Bayesian Information Criterion*) que se calcula a partir del número de parámetros ajustados con una penalización que aumenta con el tamaño de la muestra:
$$
\text{BIC} =  -2\,\text{log}\,p(\boldsymbol{y}\mid\hat{\boldsymbol{\theta}}_{\text{Bayes}}) + k\,\text{log}(n)
$$
donde $k$ es el número de parámetros del modelo y $n$ es el tamaño de la muestra.


# Ejemplo: Puntajes de Matemáticas

Los conjuntos de datos de los archivos `SB11_1.txt` contiene una muestra aleatoria del **código del departamento de ubicación del colegio** y el **puntaje de matemáticas de los estudiantes que presentaron la Prueba Saber 11 del primer semestre de 2020**. Estos datos son de carácter público y están disponibles en https://www.icfes.gov.co. 

La prueba de matemáticas se obtiene mediante un **modelo 3PL** (modelo logístico de 3 parámetros que define la probabilidad de responder correctamente de un individuo, en función de su habilidad, la dificultad del ítem, la discriminación del ítem y el pseudo-azar) y tiene una **escala de 0 a 100** (sin decimales), con **puntaje promedio de 50 puntos** y **desviación estándar 10 puntos**.

El objetivo es **construir un modelo predictivo para el puntaje de matemáticas a nivel nacional**, tomando como datos de entrenamiento los resultados del primer semestre de 2020, con el fin de **hacer inferencias sobre la población de estudiantes tanto a nivel nacional como departamental**. Por lo tanto, se toma como variable de agrupamiento el departamento de ubicación del colegio del estudiante. 


## Estructura de los datos


- $y_{i,j}$:       puntaje de matemáticas del estudiante $i$ y en departamento $j$.
- $n_j\,\,$:       número de estudiantes en el departamento $j$.
- $\bar{y}_j\,\,$: promedio muestral del departamento $j$.
- $s^2_j\,\,$:     varianza muestral del departamento $j$.


```{r}
# paquetes
suppressMessages(suppressWarnings(library(dplyr))) 
suppressMessages(suppressWarnings(library(ggplot2))) 
```


```{r}
# datos
SB11_1 <- read.csv("SB11_1_muestra.txt", sep="", fileEncoding = "UTF-8")
dim(SB11_1)
```


```{r}
# código departamentos
# https://www.fopep.gov.co/wp-content/uploads/2019/02/Tabla-C%C3%B3digos-Dane.pdf
codigo <- c(5, 8, 11, 13, 15, 17, 18, 19, 20, 23, 25, 27, 41, 44, 47, 50, 52, 54, 63, 66, 68, 70, 73, 76, 81, 85, 86, 88, 91, 94, 95, 97, 99)
nombre <- c("ANTIOQUIA", "ATLANTICO", "BOGOTA", "BOLIVAR", "BOYACA", "CALDAS", "CAQUETA", "CAUCA", "CESAR", "CORDOBA", "CUNDINAMARCA", "CHOCO", "HUILA", "LA GUAJIRA", "MAGDALENA", "META", "NARINO", "N. SANTANDER", "QUINDIO", "RISARALDA", "SANTANDER", "SUCRE", "TOLIMA", "VALLE DEL CAUCA", "ARAUCA", "CASANARE", "PUTUMAYO", "SAN ANDRES", "AMAZONAS", "GUAINIA", "GUAVIARE", "VAUPES", "VICHADA")
deptos <- data.frame(codigo, nombre)
# base de datos con nombres
SB11_1 <- left_join(x = SB11_1, y = deptos, by = "codigo")
# número de estudiantes por departamento
table(SB11_1$nombre)
# remover departamentos con un solo estudiante
SB11_1 <- SB11_1[SB11_1$nombre != "ARAUCA",]
```


```{r}
# m : número de grupos (departamentos)
# n : número de individuos (estudiantes)
(m <- length(table(SB11_1$codigo)))
(n <- sum(table(SB11_1$codigo)))
```


```{r}
# tratamiento de datos
# y  : puntaje de los estudiantes (c)
# Y  : puntaje de los estudiantes (list)
# g  : identificador secuencial de los departamentos (c)
# nj : número de estudiantes por departamento (c)
# yb : promedios por departamento (c)
# s2 : varianzas por departamento (c)
y <- SB11_1$puntaje
Y <- vector(mode = "list", length = m)
g <- rep(NA, n)
for (j in 1:m) {
  idx <- SB11_1$codigo == unique(SB11_1$codigo)[j]
  g[idx] <- j
  Y[[j]] <- y[idx]
}
# tabla
estadisticos <- SB11_1 %>% 
  group_by(codigo) %>% 
  summarise(codigo = unique(codigo), 
            nombre = unique(nombre), 
            nj = n(), 
            yb = mean(puntaje), 
            s2 = var(puntaje))
```


```{r}
head(estadisticos, n = 5)
```


```{r}
# estadísticos
nj <- estadisticos$nj
yb <- estadisticos$yb
s2 <- estadisticos$s2
```


## Modelamiento

- $\textsf{M}_1$: Modelo jerárquico Normal con medias específicas.

- $\textsf{M}_2$: Modelo jerárquico Normal con medias y varianzas específicas.


```{r}
# algoritmo modelo 1
MCMC_1 <- function(y, B, nj, yb, s2) {
  # tamaños
  n <- sum(nj)
  m <- length(nj)
  # hiperparametros
  mu0  <- 50 
  g20  <- 25
  eta0 <- 1  
  t20  <- 100
  nu0  <- 1  
  s20  <- 100
  # valores iniciales
  theta <- yb
  sig2  <- mean(s2)
  mu    <- mean(theta)
  tau2  <- var(theta)
  # almacenamiento
  THETA <- matrix(data = NA, nrow = B, ncol = m+3)
  LL    <- matrix(data = NA, nrow = B, ncol = 1)
  # cadena
  for (b in 1:B) {
    # actualizar theta
    vtheta <- 1/(1/tau2 + nj/sig2)
    theta  <- rnorm(n = m, mean = vtheta*(mu/tau2 + nj*yb/sig2), sd = sqrt(vtheta))
    # actualizar sigma^2
    sig2 <- 1/rgamma(n = 1, shape = 0.5*(nu0 + n), rate = 0.5*(nu0*s20 + sum((nj-1)*s2 + nj*(yb - theta)^2)))
    # actualizar mu
    vmu <- 1/(1/g20 + m/tau2)
    mu  <- rnorm(n = 1, mean = vmu*(mu0/g20 + m*mean(theta)/tau2), sd = sqrt(vmu)) 
    # actualizar tau^2
    tau2 <- 1/rgamma(n = 1, shape = 0.5*(eta0 + m), rate = 0.5*(eta0*t20 + (m-1)*var(theta) + m*(mean(theta) - mu)^2))
    # almacenar valores
    THETA[b,] <- c(theta, sig2, mu, tau2)
    # log-verosimilitud
    LL[b] <- sum(dnorm(x = y, mean = rep(theta, nj), sd = sqrt(sig2), log = T))
  }
  # fin de la cadena
  # salida
  colnames(THETA) <- c(paste0("theta",1:m), "sig2", "mu", "tau2")
  colnames(LL) <- c("ll")
  THETA <- as.data.frame(THETA)
  LL    <- as.data.frame(LL)
  return(list(THETA = THETA, LL = LL))
}
```


```{r}
# algoritmo modelo 2
MCMC_2 <- function(y, B, nj, yb, s2) {
  # tamaños
  n <- sum(nj)
  m <- length(nj)
  # hiperparametros
  mu0  <- 50 
  g20  <- 25
  eta0 <- 1  
  t20  <- 100
  lam0 <- 1  
  al0  <- 1
  be0  <- 1/100 
  nus0 <- 1:50  # rango en p(nu | rest)
  # valores iniciales
  theta <- yb
  sig2  <- s2  # sigma_j^2
  mu    <- mean(theta)
  tau2  <- var(theta)
  nu    <- 1
  ups2  <- 100  # sigma^2
  # almacenamiento
  THETA <- matrix(data = NA, nrow = B, ncol = 2*m+4)
  LL    <- matrix(data = NA, nrow = B, ncol = 1)
  # cadena
  for (b in 1:B) {
    # actualizar theta
    vtheta <- 1/(1/tau2 + nj/sig2)
    theta  <- rnorm(n = m, mean = vtheta*(mu/tau2 + nj*yb/sig2), sd = sqrt(vtheta))
    # actualizar sigma_j^2
    sig2 <- 1/rgamma(n = m, shape = 0.5*(nu + nj), rate = 0.5*(nu*ups2 + (nj-1)*s2 + nj*(yb - theta)^2))
    # actualizar mu
    vmu <- 1/(1/g20 + m/tau2)
    mu  <- rnorm(n = 1, mean = vmu*(mu0/g20 + m*mean(theta)/tau2), sd = sqrt(vmu))
    # actualizar tau2
    tau2 <- 1/rgamma(n = 1, shape = 0.5*(eta0+m), rate = 0.5*(eta0*t20 + (m-1)*var(theta) + m*(mean(theta) - mu)^2))
    # actualizar nu
    lpnu <- 0.5*m*nus0*log(0.5*nus0*ups2) - m*lgamma(0.5*nus0) - 0.5*nus0*sum(log(sig2)) - nus0*(lam0 + 0.5*ups2*sum(1/sig2))
    nu <- sample(x = nus0, size = 1, prob = exp(lpnu - max(lpnu)))
    # actualizar sigma^2
    ups2 <- rgamma(n = 1, shape = al0 + 0.5*m*nu, rate = be0 + 0.5*nu*sum(1/sig2))
    # almacenar
    THETA[b,] <- c(theta, sig2, mu, tau2, nu, ups2)
    # log-verosimilitud
    LL[b] <- sum(dnorm(x = y, mean = rep(theta, nj), sd = sqrt(rep(sig2, nj)), log = T))
  }
  # fin de la cadena
  # salida
  colnames(THETA) <- c(paste0("theta", 1:m), paste0("sig2", 1:m), "mu", "tau2", "nu", "ups2")
  colnames(LL) <- c("ll")
  THETA <- as.data.frame(THETA)
  LL    <- as.data.frame(LL)
  return(list(THETA = THETA, LL = LL))
}
```


```{r}
# ajuste del modelo
tictoc::tic()
set.seed(1)
M1 <- MCMC_1(y, B = 100000, nj, yb, s2)
tictoc::toc()
```


```{r}
# ajuste del modelo
tictoc::tic()
set.seed(1)
M2 <- MCMC_2(y, B = 100000, nj, yb, s2)
tictoc::toc()
```


## Log-verosimilitud


```{r, echo = F, fig.width=10, fig.height=3.5, fig.align='center'}
# cadenas
col <- RColorBrewer::brewer.pal(9,"Set1")[1:9]
yrange <- range(M1$LL$ll, M2$LL$ll)
par(mfrow = c(1,2), mar = c(2.75,2.75,1.5,0.5), mgp = c(1.7,0.7,0))
plot(M1$LL$ll, type = "p", pch = ".", cex = 1.1, col = col[1], ylim = yrange, xlab = "Iteración", ylab = "Log-verosimilitud", main = "Modelo 1")
plot(M2$LL$ll, type = "p", pch = ".", cex = 1.1, col = col[2], ylim = yrange, xlab = "Iteración", ylab = "Log-verosimilitud", main = "Modelo 2")
```


```{r, echo = F, fig.align='center'}
# gráfico log-verosimilitud
LP1 <- as.numeric(M1$LL$ll)
LP2 <- as.numeric(M2$LL$ll)
par(mfrow=c(1,1),mar=c(3,3,1,1),mgp=c(1.75,.75,0))
plot(x = NA, y = NA, ylab = "Densidad", xlab = "Log-verosimilitud", cex.axis = 0.7, xlim = range(LP1, LP2), ylim = c(0,0.12)) 
hist(LP1, freq = F, add = T, col = col[1], border = col[1])
hist(LP2, freq = F, add = T, col = col[2], border = col[2])
legend("top", legend = c("Modelo 1","Modelo 2"), fill = c(col[1],col[2]), border = c(col[1],col[2]), bty = "n", ncol = 2)
```


## Criterios de información


```{r}
# DIC
LP1        <- as.numeric(M1$LL$ll)
theta_hat  <- colMeans(M1$THETA[,1:m])
sigma2_hat <- mean(M1$THETA$sig2)
lpyth_m1   <- sum(dnorm(x = y, mean = rep(theta_hat, nj), sd = sqrt(sigma2_hat), log = T))
pDIC_m1    <- 2*(lpyth_m1 - mean(LP1))
dic_m1     <- -2*lpyth_m1 + 2*pDIC_m1 
# WAIC
lppd_m1  <- 0
pWAIC_m1 <- 0
for (i in 1:n) {
  # lppd
  tmp1 <- dnorm(x = y[i], mean = M1$THETA[,g[i]], sd = sqrt(M1$THETA$sig2))
  lppd_m1 <- lppd_m1 + log(mean(tmp1))
  # pWAIC
  tmp2 <- dnorm(x = y[i], mean = M1$THETA[,g[i]], sd =  sqrt(M1$THETA$sig2), log = T)
  pWAIC_m1 <- pWAIC_m1 + 2*(log(mean(tmp1)) - mean(tmp2))
}
waic_m1 <- -2*lppd_m1 + 2*pWAIC_m1
```


```{r}
# DIC
LP2        <- as.numeric(M2$LL$ll)
theta_hat  <- colMeans(M2$THETA[,1:m])
sigma2_hat <- colMeans(M2$THETA[,(m+1):(2*m)])
lpyth_m2   <- sum(dnorm(x = y, mean = rep(theta_hat, nj), sd = sqrt(rep(sigma2_hat, nj)), log = T))
pDIC_m2    <- 2*(lpyth_m2 - mean(LP2))
dic_m2     <- -2*lpyth_m2 + 2*pDIC_m2
# WAIC
lppd_m2  <- 0
pWAIC_m2 <- 0
for (i in 1:n) {
  # lppd
  tmp1 <- dnorm(x = y[i], mean = M2$THETA[,g[i]], sd = sqrt(M2$THETA[,m+g[i]]))
  lppd_m2 <- lppd_m2 + log(mean(tmp1))
  # pWAIC
  tmp2 <- dnorm(x = y[i], mean = M2$THETA[,g[i]], sd = sqrt(M2$THETA[,m+g[i]]), log = T)
  pWAIC_m2 <- pWAIC_m2 + 2*(log(mean(tmp1)) - mean(tmp2))
}
waic_m2 <- -2*lppd_m2 + 2*pWAIC_m2
```


```{r, echo = F}
# tabla de resumen
tab <- matrix(c(lpyth_m1, lpyth_m2,
                pDIC_m1,  pDIC_m2,
                dic_m1,   dic_m2,
                lppd_m1,  lppd_m2,
                pWAIC_m1, pWAIC_m2,
                waic_m1,  waic_m2), nrow = 6, ncol = 2, byrow = T)
colnames(tab) <- c("Modelo 1","Modelo 2")
rownames(tab) <- c("lp","pDIC","DIC","lppd","pWAIC","WAIC")
knitr::kable(x = tab, digits = 2, align = "c")
```


# Referencias {-}

```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Hoffcoverbook.jpg")
```


```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Gelmancoverbook.png")
```


```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Reichcoverbook.jpg")
```