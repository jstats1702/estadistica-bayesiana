---
title: "Modelos multinivel"
author: 
- Juan Sosa PhD
- Email   jcsosam@unal.edu.co
- GitHub  https://github.com/jstats1702 
date: ""
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introducción

El tipo más simple de **datos multinivel** tiene **dos niveles**, a saber, **grupos** y **unidades dentro de los grupos**. 

Se denota con $y_{i,j}$ la observación de la unidad $i$ en el grupo $j$, para $i = 1,\ldots,n_j$ y $j=1,\ldots,m$, donde $m$ es el número de grupos y $n = \sum_{j=1}^m n_j$ es el tamaño de la muestra.

El **conjunto de datos** es $\boldsymbol{y} = (\boldsymbol{y}_1,\ldots,\boldsymbol{y}_m)$, donde $\boldsymbol{y}_j=(y_{1,j},\ldots,y_{n_j,j})$ son las observaciones del grupo $j$, para $j=1,\ldots,m$.


# Modelo Normal multinivel

Un modelo popular para caracterizar la **heterogeneidad de las medias** en varias poblaciones es el **modelo jerárquico Normal**, en el cual la **variabilidad dentro y entre** se modela usando **distribuciones Normales**:

- **Caracterización dentro de los grupos:**
$$
y_{i, j}\mid\theta_j,\sigma^2 \stackrel{\text {iid}}{\sim} \textsf{N}\left(\theta_j,\sigma^2\right)
$$
- **Caracterización entre los grupos:**
$$
\theta_{j}\mid\mu,\tau^2 \stackrel{\text {iid}}{\sim} \textsf{N}\left(\mu,\tau^2\right)
$$
- **Distribución previa:**
$$
p(\sigma^2,\mu,\tau^2) = p(\sigma^2)\,p(\mu)\,p(\tau^2)
$$
donde
$$
\sigma^2\sim\textsf{GI}\left(\tfrac{\nu_0}{2},\tfrac{\nu_0\,\sigma^2_0}{2}\right)\qquad\mu\sim\textsf{N}(\mu_0,\gamma_0^2)\qquad\tau^2\sim\textsf{GI}\left(\tfrac{\eta_0}{2},\tfrac{\eta_0\,\tau^2_0}{2}\right)
$$
- Los **parámetros** del modelo son $\boldsymbol{\theta}=(\theta_1,\ldots,\theta_m,\sigma^2,\mu,\tau^2)$.

- Los **hiperparámetros** del modelo son $(\nu_0,\sigma^2_0,\mu_0,\gamma_0^2,\eta_0,\tau^2_0)$.


## Estimación

La estimación de los parámetros del modelo se puede hacer por medio de un **muestreador de Gibbs** para obtener muestras de la distribución posterior $p(\boldsymbol{\theta}\mid\boldsymbol{y})$.

- **Distribución posterior**:
$$
\begin{aligned}
p(\boldsymbol{\theta} \mid \boldsymbol{y}) &\propto p(\boldsymbol{y} \mid \boldsymbol{\theta})\, p(\boldsymbol{\theta}) \\
&=\prod_{j=1}^m\prod_{i=1}^{n_j} \textsf{N}\left(y_{i, j} \mid \theta_{j}, \sigma^{2}\right) \\
&\quad\quad\times \prod_{j=1}^m \textsf{N}\left(\theta_{j} \mid \mu, \tau^{2}\right) \times
\textsf{GI}\left(\sigma^{2} \mid \tfrac{\nu_{0}}{2}, \tfrac{\nu_{0}\,\sigma_{0}^{2}}{2} \right) \\
&\quad\quad\quad\quad\times \textsf{N}\left(\mu \mid \mu_{0}, \gamma_{0}^{2}\right) \times \textsf{GI}\left(\tau^{2} \mid \tfrac{\eta_{0}}{2}, \tfrac{\eta_{0}\,\tau_{0}^{2}}{2}\right)
\end{aligned}
$$

- **Distribuciones condicionales completas**:
$$
\begin{aligned}
\theta_{j} \mid \text { resto } &\sim \textsf{N}\left( \frac{\mu / \tau^{2} + n_{j} \bar{y}_{j} / \sigma^{2}}{1 / \tau^{2} + n_{j} /\sigma^{2}}, \frac{1}{1 / \tau^{2} + n_{j} /\sigma^{2}}\right) \\
\sigma^{2} \mid \text { resto } &\sim\textsf{GI}\left( \frac{\nu_{0}+\sum_{j=1}^m n_{j}}{2}, \frac{\nu_{0} \sigma_{0}^{2}+\sum_{j=1}^m \sum_{i=1}^{n_j}\left(y_{i, j}-\theta_{j}\right)^{2}}{2}\right) \\
\mu \mid \text { resto }&\sim\textsf{N}\left( \frac{\mu_{0} / \gamma_{0}^{2} + m \bar{\theta} / \tau^{2}}{1 / \gamma_{0}^{2} + m / \tau^{2}}, \frac{1}{1 / \gamma_{0}^{2} + m / \tau^{2}}\right) \\
\tau^{2} \mid \text { resto }&\sim\textsf{ GI }\left(\frac{\eta_{0}+m}{2}, \frac{\eta_{0} \tau_{0}^{2}+\sum_{j=1}^m\left(\theta_{j}-\mu\right)^{2}}{2}\right)
\end{aligned}
$$

# Ejemplo: Puntajes de Matemáticas

La base de datos contiene la información de una **muestra aleatoria simple** de los **estudiantes que presentaron la Prueba Saber 11 en 2023-2**. 

La **prueba de matemáticas** está diseñada con una **escala de 0 a 100** (sin decimales), un **puntaje promedio de 50** y una **desviación estándar de 10 puntos**.

El objetivo es **construir un modelo para el puntaje de matemáticas a nivel nacional**, tomando como datos de entrenamiento los resultados del segundo semestre de 2023, con el fin de **hacer inferencias sobre la población de estudiantes tanto a nivel nacional como departamental**. 

Por lo tanto, se toma el **departamento de residencia del estudiante como variable de agrupamiento**. 

Los datos son públicos y están disponibles en este [enlace](https://www.icfes.gov.co/data-icfes/).

## Estructura de los datos

- $y_{i,j}$:       puntaje de matemáticas del estudiante $i$ y en departamento $j$.
- $n_j\,\,$:       número de estudiantes en el departamento $j$.
- $\bar{y}_j\,\,$: promedio muestral del departamento $j$.
- $s^2_j\,\,$:     varianza muestral del departamento $j$.

## Tratamiento de datos

```{r}
# datos
dat <- read.csv("C:/Users/User/Dropbox/UN/estadistica_bayesiana/SB11_20232_muestra.txt", sep=";")
dat <- dat[order(dat$ESTU_COD_RESIDE_MCPIO), ]
# dimensión de la base
dim(dat)
# distribución de frecuencias
table(dat$ESTU_DEPTO_RESIDE)
```

```{r}
# paquetes
suppressMessages(suppressWarnings(library(dplyr))) 
suppressMessages(suppressWarnings(library(ggplot2))) 
```

```{r}
# m : número de grupos (departamentos)
# n : número de individuos (estudiantes)
(m <- length(table(dat$ESTU_DEPTO_RESIDE)))
(n <- sum(table(dat$ESTU_DEPTO_RESIDE)))
```

```{r}
# tratamiento de datos
# y  : puntaje de los estudiantes (c)
# Y  : puntaje de los estudiantes (list)
# g  : identificador secuencial de los departamentos (c)
# nj : número de estudiantes por departamento (c)
# yb : promedios por departamento (c)
# s2 : varianzas por departamento (c)
y <- dat$PUNT_MATEMATICAS
Y <- vector(mode = "list", length = m)
g <- rep(NA, n)
for (j in 1:m) {
  idx <- dat$ESTU_COD_RESIDE_DEPTO == sort(unique(dat$ESTU_COD_RESIDE_DEPTO))[j]
  g[idx] <- j
  Y[[j]] <- y[idx]
}
# tabla
estadisticos <- dat %>% 
  group_by(ESTU_COD_RESIDE_DEPTO) %>% 
  summarise(
    codigo = first(ESTU_COD_RESIDE_DEPTO),
    nombre = first(ESTU_DEPTO_RESIDE),
    nj = n(), 
    yb = mean(PUNT_MATEMATICAS), 
    s2 = var(PUNT_MATEMATICAS)
  ) %>% 
  ungroup() %>% 
  select(-ESTU_COD_RESIDE_DEPTO)
```

```{r}
head(estadisticos, n = 5)
```

```{r}
# estadísticos
nj <- estadisticos$nj
yb <- estadisticos$yb
s2 <- estadisticos$s2
```

## Análisis exploratorio

```{r, fig.align='center'}
# Descargar shape files
# https://sites.google.com/site/seriescol/shapes
shp <- sf::st_read("depto.shp", quiet = T)
# promedio por departamento
dat_map <- estadisticos[,c("codigo","yb")]
pd <- dat_map
pd$codigo <- as.character(pd$codigo)
pd$codigo[pd$codigo == "5"] <- "05"
pd$codigo[pd$codigo == "8"] <- "08"
colnames(pd) <- c("DPTO","Media")
# plot
inner_join(x = shp, y = pd, by = c("DPTO")) %>% 
  select(DPTO, Media, geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Media), size = 0.125, color = "#b2b2b2") +
    theme_bw() + 
    xlab("Longitud") + ylab("Latitud") +
    labs(title = "")
```

```{r, fig.width=7, fig.height=9, fig.align='center'}
# ranking basado en el promedio muestral
par(mfrow = c(1,1), mar = c(4,10,1.5,1), mgp = c(2.5,0.75,0))
plot(x = c(0,100), y = c(1,m), type = "n", xlab = "Puntaje", ylab = "", main = expression(italic("Ranking (promedio muestral)")), yaxt = "n")
abline(h = 1:m, col = "lightgray", lwd = 1)
abline(v = 50,col = "gray", lwd = 3)
for (l in 1:m) {
  j <- order(yb)[l]
  points(x = Y[[j]], y = rep(l, nj[j]), pch = 16, cex = 0.4)
}
lines(x = yb[order(yb)], y = 1:m, type = "p", col = 4, pch = 16, cex = 1.1)
lines(x = yb[order(yb)], y = 1:m, type = "l", col = adjustcolor(4, 0.3))
axis(side = 2, at = 1:m, labels = estadisticos$nombre[order(yb)], las = 2)
```


```{r, fig.width=8, fig.height=4, fig.align='center'}
par(mfrow = c(1,2), mar = c(3,3,1.5,1), mgp = c(1.75,0.75,0)) 
hist(yb, freq = F, main = "", xlab = "Promedio", ylab = "Densidad", border = adjustcolor(4, 0.), col = adjustcolor(4, 0.3))
abline(v = mean(y), col = "gray", lwd = 3)
plot(nj, yb, xlab = "Tamaño del grupo", ylab = "Promedio", pch = 16, cex = 1.2, col = adjustcolor(4, 0.6))
abline(h = mean(y), col = "gray", lwd = 3)
```

Es común que los grupos con promedios muestrales muy altos o muy bajos correspondan a aquellos grupos con tamaños muestrales bajos.

## Distribución previa

Teniendo en cuenta la información de la prueba, el modelo se ajusta utilizando los siguientes hiperparámetros: 
$$
\mu_0 = 50\,,\qquad
\gamma^2_0 = 10^2\,,\qquad
\eta_0 = 1\,,\qquad
\tau^2_0 = 10^2\,,\qquad
\nu_0 = 1\,,\qquad
\sigma^2_0 = 10^2\,.
$$

```{r}
# hiperparámetros
mu0  <- 50 
g20  <- 10^2
eta0 <- 1  
t20  <- 10^2
nu0  <- 1  
s20  <- 10^2
```

## Ajuste del modelo

```{r}
MCMC1 <- function(B, nj, yb, s2, mu0, g20, eta0, t20, nu0, s20) {
  # ajustes
  ncat <- floor(B/10) 
  # tamaños
  n <- sum(nj)
  m <- length(nj)
  # almacenamiento
  THETA <- matrix(data = NA, nrow = B, ncol = m+4)
  # valores iniciales
  theta <- yb
  sig2  <- mean(s2)
  mu    <- mean(theta)
  tau2  <- var(theta)
  # cadena
  for (b in 1:B) {
    # actualizar \theta
    vtheta <- 1/(1/tau2 + nj/sig2)
    theta  <- rnorm(n = m, mean = vtheta*(mu/tau2 + nj*yb/sig2), sd = sqrt(vtheta))
    # actualizar \sigma^2
    sig2 <- 1/rgamma(n = 1, shape = 0.5*(nu0 + n), rate = 0.5*(nu0*s20 + sum((nj-1)*s2 + nj*(yb - theta)^2)))
    # actualizar \mu
    vmu <- 1/(1/g20 + m/tau2)
    mu  <- rnorm(n = 1, mean = vmu*(mu0/g20 + m*mean(theta)/tau2), sd = sqrt(vmu)) 
    # actualizar \tau^2
    tau2 <- 1/rgamma(n = 1, shape = 0.5*(eta0 + m), rate = 0.5*(eta0*t20 + (m-1)*var(theta) + m*(mean(theta) - mu)^2))
    # log-verosimilitud
    ll <- sum(dnorm(x = y, mean = rep(theta, nj), sd = sqrt(sig2), log = T))
    # almacenar valores
    THETA[b,] <- c(theta, sig2, mu, tau2, ll)
    # progreso
    if (b%%ncat == 0)
        cat(100*round(b/B, 1), "% completado ... \n", sep = "")
  }
  # fin de la cadena
  # salida
  colnames(THETA) <- c(paste0("theta",1:m), "sig2", "mu", "tau2", "ll")
  THETA <- as.data.frame(THETA)
  return(list(THETA = THETA))
}
```

```{r}
# ajuste del modelo
tictoc::tic()
set.seed(123)
chain1 <- MCMC1(B = 10000, nj, yb, s2, mu0, g20, eta0, t20, nu0, s20)
tictoc::toc()
```

## Convergencia

```{r, echo = F, fig.width=10, fig.height=7, fig.align='center'}
# cadenas
par(mfrow = c(2,2), mar = c(2.75,2.75,1.5,0.5), mgp = c(1.7,0.7,0))
plot(chain1$THETA$ll,   type = "p", pch = ".", cex = 1.1, col = 4, xlab = "Iteracion", ylab = "Log-verosimilitud", main = expression(italic("Cadena Log-verosimilitud")))
plot(chain1$THETA$sig2, type = "p", pch = ".", cex = 1.1, col = 4, xlab = "Iteracion", ylab = expression(sigma^2), main = expression(italic(paste("Cadena de ", sigma^2, sep = ""))))
plot(chain1$THETA$mu,   type = "p", pch = ".", cex = 1.1, col = 4, xlab = "Iteracion", ylab = expression(mu), main = expression(italic(paste("Cadena de ", mu, sep = ""))))
plot(chain1$THETA$tau2, type = "p", pch = ".", cex = 1.1, col = 4, xlab = "Iteracion", ylab = expression(tau^2), main = expression(italic(paste("Cadena de ", tau^2, sep = ""))))
```

```{r}
# tamaños efectivos de muestra
neff1 <- coda::effectiveSize(chain1$THETA)
summary(neff1)
```

```{r}
# coeficiente de variación de Monte Carlo (%)
EEMC1 <- apply(X = chain1$THETA, MARGIN = 2, FUN = sd)/sqrt(neff1)
CVMC1 <- 100*abs(EEMC1/colMeans(chain1$THETA))
round(summary(CVMC1), 4)
```

```{r, echo = F, fig.width=5, fig.height=4, fig.align='center'}
par(mfrow = c(1,1), mar = c(2.75,2.75,2.5,0.5), mgp = c(1.7,0.7,0))
set.seed(123)
boxplot(CVMC1, col = 0, outline = F, ylim = range(CVMC1), ylab = "CVMC", main = expression(italic("Coeficiente de Variación de MC")))
points(x = jitter(x = rep(1, m+4), factor = 6), y = CVMC1, pch = 16, col = adjustcolor(4, 0.3))
```

## Inferencia

Se define $\eta$ como la proporción de intravarianza: $\eta = 100\cdot\frac{\sigma^2}{\sigma^2+\tau^2}\%$.

```{r, echo = F, fig.width=5, fig.height=4, fig.align='center'}
# inferencia sobre \sigma^2, \mu, \tau^2, \eta
PAR <- cbind(100*chain1$THETA$sig2/(chain1$THETA$sig2 + chain1$THETA$tau2), chain1$THETA$mu, sqrt(chain1$THETA$sig2),  sqrt(chain1$THETA$tau2))
par(mfrow = c(1,1), mar = c(2.75,2.75,2.5,0.5), mgp = c(1.7,0.7,0))
# eta
hist(PAR[,4], freq = F, xlab = expression(eta), ylab = "Densidad", main = expression(italic(paste("Distribución posterior de ", eta, sep = ""))), border = "gray90", col = "gray90")
abline(v = quantile(PAR[,4], probs = c(0.025,0.5,0.975)), col = c(4,2,4), lty = c(1,2,1), lwd = c(2,1,2))
legend("topright", legend = c("Distr. Posterior", "Media", "IC 95%"), fill = c("gray90", 2, 4), col = c("gray90", 2, 4), border = c("gray90", 2, 4), bty = "n")
```

- El 90.0% de la variabilidad total en los puntajes se explica por las diferencias dentro de los departamentos.  
- La media global de los puntajes es cercana a 50.  
- El 99.7% de los puntajes individuales dentro de los departamentos se encuentran a una distancia máxima de \( 3 \times 12.1 = 36.3 \) puntos.  
- El 99.7% de los promedios de puntajes entre departamentos están separados por una distancia máxima de \( 3 \times 4.0 = 12.0 \) puntos.

```{r, echo = F}
tab <- rbind(colMeans(PAR), 100*abs(apply(X = PAR, MARGIN = 2, FUN = sd)/colMeans(PAR)), apply(X = PAR, MARGIN = 2, FUN = quantile, probs = c(0.025, 0.975)))
rownames(tab) <- c("Media","CV(%)","Q2.5%","Q97.5%")
colnames(tab) <- c("eta","mu","sig", "tau")
knitr::kable(x = t(tab), digits = 1, align = "c")
```

## Ranking

```{r, echo = F, fig.width=8, fig.height=10, fig.align='center'}
# ranking Bayesiano
ids2 <- estadisticos$nombre
that <- colMeans(chain1$THETA[,1:m])
ic1  <- apply(X = chain1$THETA[,1:m], MARGIN = 2, FUN = function(x) quantile(x, c(0.025,0.975)))
ranking <- order(that) 
ids2 <- ids2[ ranking]
that <- that[ ranking]
ic1  <- ic1 [,ranking]
colo <- rep(2,m)
colo[which(ic1[1,]>50)] <- 1
colo[which(ic1[2,]<50)] <- 3
colo <- c("royalblue","black","red")[colo]
# gráfico
par(mfrow = c(1,1), mar = c(4,10,1.5,1), mgp = c(2.5,0.75,0))
plot(NA, NA, xlab = "Puntaje", ylab = "", main = expression(italic("Ranking Bayesisano")), xlim = c(0,100), ylim = c(1,m), cex.axis = 0.75, yaxt = "n")
axis(side = 2, at = 1:m, labels = ids2, las = 2)
abline(v = 50,  col = "gray", lwd = 3)
abline(h = 1:m, col = "lightgray", lwd = 1)
for (j in 1:m) {
  segments(x0 = ic1[1,j], y0 = j, x1 = ic1[2,j], y1 = j, col = colo[j])
  lines(x = that[j], y = j, type = "p", pch = 16, cex = 0.8, col = colo[j])
}
```

```{r, echo = F, fig.width=7, fig.height=5, fig.align='center'}
# CV Bayesiano
that <- apply(X = chain1$THETA[,1:m], MARGIN = 2, FUN = mean)
shat <- apply(X = chain1$THETA[,1:m], MARGIN = 2, FUN = sd)
ranking <- order(that, decreasing = T)
cv_b <- 100*abs(shat/that)[ranking]
ids2 <- estadisticos$nombre[ranking]
# gráfico
par(mfrow = c(1,1), mar = c(6.5,4,1.5,1), mgp = c(2.5,.75,0))
plot (1:m, cv_b, xlab = "", ylab = "CV(%)", pch = 16, type = "b", col = 4, xlim = c(1,m), ylim = c(0,15), cex = 0.75, cex.axis = 0.75, xaxt = "n", main = "Coeficiente de Variación")
axis(side = 1, at = 1:m, labels = F)
text(x = (1:m) + 0.3, y = par("usr")[3] - 1.5, labels = ids2, srt = 70, pos = 2, xpd = T, cex = 0.75)
abline(v = 1:m, col = "gray95", lwd = 1, lty = 3)
abline(h = 5, lty = 2, col = 3)
abline(h = 10, lty = 2, col = "#FFA500")
abline(h = 15, lty = 2, col = 2)
```

## Contracción 

La **contracción** (*shrinkage*) es un fenómeno donde las estimaciones de ciertos parámetros tienden a "acercarse" o "ajustarse" hacia un valor central o promedio. Este efecto ocurre generalmente debido a la **influencia de la previa** o a la **estructura jerárquica del modelo**. 

La contracción ayuda a **proporcionar estimaciones más moderadas y estables**, especialmente en escenarios donde los datos son limitados. 

Este ajuste **mejora la robustez de los resultados** al equilibrar la información observada con la información previa o el contexto global del modelo.

La contracción genera dependencia entre los grupos al asumir que sus parámetros comparten una distribución común. Esto provoca que las estimaciones de los **grupos con poca información se ajusten hacia el promedio global**, mientras que los **grupos con mayor cantidad de información se apoyen más en sus propios datos**.

```{r, echo = F, fig.width=8, fig.height=4, fig.align='center'}
# contracción
par(mfrow = c(1,2), mar = c(3,3,1.5,1), mgp = c(1.75,0.75,0))
# theta hat vs. promedio muestral
theta_hat <- apply(X = chain1$THETA[,1:m], MARGIN = 2, FUN = mean)
plot(x = NA, y = NA, xlim = range(yb,theta_hat), ylim = range(yb,theta_hat), xlab = expression(bar(italic(y))), ylab = expression(hat(theta)), main = "")
abline(a = 0, b = 1, col = "gray", lwd = 2)
lines(x = yb, y = theta_hat, type = "p", pch = 16, cex = 1.2, col = adjustcolor(4, 0.6))
# diferencia vs. tamaño de muestra
plot(x = NA, y = NA, xlim = range(nj), ylim = c(-1,1)*max(abs(range(yb-theta_hat))), xlab = "Tamaño de la muestra", ylab = expression( bar(italic(y))-hat(theta)), main = "")
abline(h = 0, col = "gray", lwd = 2)
lines(x = nj, y = yb-theta_hat, type = "p", pch = 16, cex = 1.2, col = adjustcolor(4, 0.6))
```

```{r, echo = F, fig.width=5, fig.height=4, fig.align='center'}
# contracción
par(mfrow = c(1,1), mar = c(3,3,1.5,1), mgp = c(1.75,0.75,0))
plot(x = NA, y = NA, xlim = range(yb,theta_hat), ylim = c(1,4), yaxt = "n", cex.axis = 0.8, xlab = "Puntaje", ylab = "", main = "")
axis(side = 2, at = c(2,3), labels = c(expression(hat(theta)), expression(bar(y))), las = 1)
abline(h = c(2,3), col = c(4,2), lwd = 2)
for (j in 1:m)
  segments(x0 = theta_hat[j], y0 = 2, x1 = yb[j], y1 = 3, 1)
```

# Modelo Normal con medidas y varianzas especificas

Una extensión directa del modelo Normal multinivel consiste en permitir que tanto la tendencia como la variabilidad de los grupos sea específica para cada grupo.

- **Caracterización dentro de los grupos:**
$$
y_{i, j}\mid\theta_j,\sigma_j^2 \stackrel{\text {iid}}{\sim} \textsf{N}\left(\theta_j,\sigma_j^2\right)
$$

- **Caracterización entre los grupos:**
$$
\theta_{j}\mid\mu,\tau^2 \stackrel{\text {iid}}{\sim} \textsf{N}\left(\mu,\tau^2\right)
\qquad
\sigma_j^2\mid\nu,\sigma^2 \stackrel{\text {iid}}{\sim}\textsf{GI}\left(\tfrac{\nu}{2},\tfrac{\nu\,\sigma^2}{2}\right)
$$

- **Distribución previa**:
$$
p(\mu,\tau^2,\nu,\sigma^2) = p(\mu)\,p(\tau^2)\,p(\nu)\,p(\sigma^2)
$$
donde
$$
\mu\sim\textsf{N}(\mu_0,\gamma_0^2)\qquad\tau^2\sim\textsf{GI}\left(\tfrac{\eta_0}{2},\tfrac{\eta_0\,\tau^2_0}{2}\right)
\qquad p(\nu)\propto e^{-\lambda_0\,\nu}\qquad \sigma^2\sim\textsf{Gamma}(\alpha_0,\beta_0)
$$
- Los **parámetros** del modelo son $\boldsymbol{\theta}=(\theta_1,\ldots,\theta_m,\sigma^2_1,\ldots,\sigma^2_m,\mu,\tau^2,\nu,\sigma^2)$.

- Los **hiperparámetros** del modelo son $(\mu_0,\gamma_0^2,\eta_0,\tau^2_0, \lambda_0,\alpha_0,\beta_0)$.

## Estimación

La estimación de los parámetros del modelo se puede hacer por medio de un **muestreador de Gibbs** para obtener muestras de la distribución posterior $p(\boldsymbol{\theta}\mid\boldsymbol{y})$.

- **Distribución posterior**:
$$
\begin{aligned}
p(\boldsymbol{\theta} \mid \boldsymbol{y}) &\propto p(\boldsymbol{y} \mid \boldsymbol{\theta})\, p(\boldsymbol{\theta}) \\
&= \prod_{j=1}^m\prod_{i=1}^{n_j} \textsf{N}\left(y_{i, j} \mid \theta_{j}, \sigma_j^{2}\right) \\
&\quad\quad\times \prod_{j=1}^m \textsf{N}\left(\theta_{j} \mid \mu, \tau^{2}\right) \times \prod_{j=1}^m \textsf{GI}\left(\sigma^2_{j} \mid \tfrac{\nu}{2}, \tfrac{\nu\,\sigma^{2}}{2}\right) \\
&\quad\quad\quad\times \textsf{N}\left(\mu \mid \mu_{0}, \gamma_{0}^{2}\right) \times \textsf{GI}\left(\tau^{2} \mid \tfrac{\eta_{0}}{2}, \tfrac{\eta_{0}\,\tau_{0}^{2}}{2}\right) \\
&\quad\quad\quad\quad\times e^{-\lambda_0\,\nu} \times \textsf{G}(\sigma^2\mid\alpha_0,\beta_0)
\end{aligned}
$$

- **Distribuciones condicionales completas**:
$$
\begin{aligned}
\theta_{j} \mid \text { resto } &\sim\textsf{N}\left(\frac{\mu / \tau^{2} + n_{j} \bar{y}_{j} / \sigma_j^{2}}{1 / \tau^{2} + n_{j} /\sigma_j^{2}}, \frac{1}{1 / \tau^{2} + n_{j} /\sigma_j^{2}}\right) \\
\sigma_{j}^{2} \,\mid\, \text { resto } &\sim\textsf{GI}\left(\frac{\nu+n_{j}}{2}, \frac{\nu \sigma^{2}+\sum_{i=1}^{n_j}\left(y_{i, j}-\theta_{j}\right)^{2}}{2}\right) \\
\mu \mid \text { resto } &\sim\textsf{N}\left(\frac{\mu_{0} / \gamma_{0}^{2} + m \bar{\theta} / \tau^{2}}{1 / \gamma_{0}^{2} + m / \tau^{2}}, \frac{1}{1 / \gamma_{0}^{2} + m / \tau^{2}}\right) \\
\tau^{2} \mid \text { resto } &\sim\textsf{ GI }\left(\frac{\eta_{0}+m}{2}, \frac{\eta_{0} \tau_{0}^{2}+\sum_{j=1}^m\left(\theta_{j}-\mu\right)^{2}}{2}\right)\\
\sigma^{2} \mid \text { resto }&\sim\textsf{G}\left(\alpha_0+\frac{m \nu}{2},  \beta_0+\frac{\nu}{2} \sum_{j=1}^m \frac{1}{\sigma_{j}^2}\right) 
\end{aligned}
$$

La **distribución condicional completa de $\nu$ no tiene una forma cerrada** conocida:
$$
p\left(\nu \mid \text { resto }\right) \propto\left[\frac{\left(\nu\,\sigma^{2} / 2\right)^{\nu / 2}}{\Gamma\left(\nu / 2\right)}\right]^{m}\left[\prod_{j=1}^m \frac{1}{\sigma_j^{2}}\right]^{\nu / 2} {\exp}\left\{-\nu\left(\lambda_0 + \frac{\sigma^{2}}{2} \sum_{j=1}^m \frac{1}{\sigma_{j}^{2}}\right)\right\},
$$
o en **escala log**,
$$
\log p\left(\nu \mid \text { resto }\right) \propto \frac{m\,\nu}{2} \log(\nu\,\sigma^{2} / 2) - m\log\Gamma(\nu/2) -\frac{\nu}{2} \sum_{j=1}^m \log(\sigma_j^{2}) - \nu\left(\lambda_0 + \frac{\sigma^{2}}{2} \sum_{j=1}^m \frac{1}{\sigma_{j}^{2}}\right).
$$

Para generar valores de $p(\nu \mid \text{resto})$ **se calcula esta distribución en escala log para un rango de valores de $\nu$**, se normaliza la distribución discreta resultante, y luego se muestrea un valor del rango de valores establecido de acuerdo con las probabilidades obtenidas.

# Ejemplo: Puntajes de Matemáticas (cont.)

La base de datos contiene la información de una **muestra aleatoria simple** de los **estudiantes que presentaron la Prueba Saber 11 en 2023-2**. 

La **prueba de matemáticas** está diseñada con una **escala de 0 a 100** (sin decimales), un **puntaje promedio de 50** y una **desviación estándar de 10 puntos**.

El objetivo es **construir un modelo para el puntaje de matemáticas a nivel nacional**, tomando como datos de entrenamiento los resultados del segundo semestre de 2023, con el fin de **hacer inferencias sobre la población de estudiantes tanto a nivel nacional como departamental**. 

Por lo tanto, se toma el **departamento de residencia del estudiante como variable de agrupamiento**. 

Los datos son públicos y están disponibles en este [enlace](https://www.icfes.gov.co/data-icfes/).

## Estructura de los datos

- $y_{i,j}$:       puntaje de matemáticas del estudiante $i$ y en departamento $j$.
- $n_j\,\,$:       número de estudiantes en el departamento $j$.
- $\bar{y}_j\,\,$: promedio muestral del departamento $j$.
- $s^2_j\,\,$:     varianza muestral del departamento $j$.

## Tratamiento de datos

```{r}
# datos
dat <- read.csv("C:/Users/User/Dropbox/UN/estadistica_bayesiana/SB11_20232_muestra.txt", sep=";")
dat <- dat[order(dat$ESTU_COD_RESIDE_MCPIO), ]
# dimensión de la base
dim(dat)
# distribución de frecuencias
table(dat$ESTU_DEPTO_RESIDE)
```

```{r}
# paquetes
suppressMessages(suppressWarnings(library(dplyr))) 
suppressMessages(suppressWarnings(library(ggplot2))) 
```

```{r}
# m : número de grupos (departamentos)
# n : número de individuos (estudiantes)
(m <- length(table(dat$ESTU_DEPTO_RESIDE)))
(n <- sum(table(dat$ESTU_DEPTO_RESIDE)))
```

```{r}
# tratamiento de datos
# y  : puntaje de los estudiantes (c)
# Y  : puntaje de los estudiantes (list)
# g  : identificador secuencial de los departamentos (c)
# nj : número de estudiantes por departamento (c)
# yb : promedios por departamento (c)
# s2 : varianzas por departamento (c)
y <- dat$PUNT_MATEMATICAS
Y <- vector(mode = "list", length = m)
g <- rep(NA, n)
for (j in 1:m) {
  idx <- dat$ESTU_COD_RESIDE_DEPTO == sort(unique(dat$ESTU_COD_RESIDE_DEPTO))[j]
  g[idx] <- j
  Y[[j]] <- y[idx]
}
# tabla
estadisticos <- dat %>% 
  group_by(ESTU_COD_RESIDE_DEPTO) %>% 
  summarise(
    codigo = first(ESTU_COD_RESIDE_DEPTO),
    nombre = first(ESTU_DEPTO_RESIDE),
    nj = n(), 
    yb = mean(PUNT_MATEMATICAS), 
    s2 = var(PUNT_MATEMATICAS)
  ) %>% 
  ungroup() %>% 
  select(-ESTU_COD_RESIDE_DEPTO)
```

```{r}
head(estadisticos, n = 5)
```

```{r}
# estadísticos
nj <- estadisticos$nj
yb <- estadisticos$yb
s2 <- estadisticos$s2
```

## Distribución previa

Teniendo en cuenta la información de la prueba, el modelo se ajusta utilizando los siguientes hiperparámetros: 
$$
\mu_0 = 50\,,\qquad
\gamma^2_0 = 10^2\,,\qquad
\eta_0 = 1\,,\qquad
\tau^2_0 = 10^2\,,\qquad
\lambda_0 = 1\,,\qquad
\alpha_0 = 1\,,\qquad
\beta_0 = 1/10^2\,.
$$

```{r}
  # hiperparámetros
  mu0  <- 50 
  g20  <- 10^2
  eta0 <- 1  
  t20  <- 10^2
  lam0 <- 1  
  al0  <- 1
  be0  <- 1/10^2 
  nus0 <- 1:50  # rango para p(nu | rest)
```

## Ajuste del modelo

```{r}
MCMC2 <- function(B, nj, yb, s2, mu0, g20, eta0, t20, lam0, al0, be0, nus0) {
  # ajustes
  ncat <- floor(B/10) 
  # tamaños
  n <- sum(nj)
  m <- length(nj)
  # almacenamiento
  THETA <- matrix(data = NA, nrow = B, ncol = 2*m+5)
  # valores iniciales
  theta <- yb
  sig2  <- s2  # \sigma_j^2
  mu    <- mean(theta)
  tau2  <- var(theta)
  nu    <- 1
  ups2  <- 100  # \sigma^2
  # cadena
  for (b in 1:B) {
    # actualizar \theta
    vtheta <- 1/(1/tau2 + nj/sig2)
    theta  <- rnorm(n = m, mean = vtheta*(mu/tau2 + nj*yb/sig2), sd = sqrt(vtheta))
    # actualizar \sigma_j^2
    sig2 <- 1/rgamma(n = m, shape = 0.5*(nu + nj), rate = 0.5*(nu*ups2 + (nj-1)*s2 + nj*(yb - theta)^2))
    # actualizar \mu
    vmu <- 1/(1/g20 + m/tau2)
    mu  <- rnorm(n = 1, mean = vmu*(mu0/g20 + m*mean(theta)/tau2), sd = sqrt(vmu))
    # actualizar \tau2
    tau2 <- 1/rgamma(n = 1, shape = 0.5*(eta0+m), rate = 0.5*(eta0*t20 + (m-1)*var(theta) + m*(mean(theta) - mu)^2))
    # actualizar \nu
    lpnu <- 0.5*m*nus0*log(0.5*nus0*ups2) - m*lgamma(0.5*nus0) - 0.5*nus0*sum(log(sig2)) - nus0*(lam0 + 0.5*ups2*sum(1/sig2))
    nu <- sample(x = nus0, size = 1, prob = exp(lpnu - max(lpnu)))
    # actualizar \sigma^2
    ups2 <- rgamma(n = 1, shape = al0 + 0.5*m*nu, rate = be0 + 0.5*nu*sum(1/sig2))
    # log-verosimilitud
    ll <- sum(dnorm(x = y, mean = rep(theta, nj), sd = sqrt(rep(sig2, nj)), log = T))
    # almacenar
    THETA[b,] <- c(theta, sig2, mu, tau2, nu, ups2, ll)
    # progreso
    if (b%%ncat == 0)
        cat(100*round(b/B, 1), "% completado ... \n", sep = "")
  }
  # fin de la cadena
  # salida
  colnames(THETA) <- c(paste0("theta", 1:m), paste0("sig2", 1:m), "mu", "tau2", "nu", "ups2", "ll")
  THETA <- as.data.frame(THETA)
  return(list(THETA = THETA))
}
```

```{r}
# ajuste del modelo 2
tictoc::tic()
set.seed(123)
chain2 <- MCMC2(B = 10000, nj, yb, s2, mu0, g20, eta0, t20, lam0, al0, be0, nus0)
tictoc::toc()
```

## Convergencia

```{r, fig.width=10, fig.height=3.5, fig.align='center'}
# cadenas
col <- RColorBrewer::brewer.pal(9,"Set1")[1:9]
yrange <- range(chain1$THETA$ll, chain2$THETA$ll)
par(mfrow = c(1,2), mar = c(2.75,2.75,1.5,0.5), mgp = c(1.7,0.7,0))
plot(chain1$THETA$ll, type = "p", pch = ".", cex = 1.1, col = col[2], ylim = yrange, xlab = "Iteración", ylab = "Log-verosimilitud", main = expression(italic("Modelo 1")))
abline(h = mean(chain1$THETA$ll), lwd = 3, col = col[2])
plot(chain2$THETA$ll, type = "p", pch = ".", cex = 1.1, col = col[1], ylim = yrange, xlab = "Iteración", ylab = "Log-verosimilitud", main = expression(italic("Modelo 2")))
abline(h = mean(chain2$THETA$ll), lwd = 3, col = col[1])
```

```{r}
# tamaños efectivos de muestra
neff2 <- coda::effectiveSize(chain2$THETA)
summary(neff2)
```

```{r}
# coeficiente de variación de Monte Carlo (%)
EEMC2 <- apply(X = chain2$THETA, MARGIN = 2, FUN = sd)/sqrt(neff2)
CVMC2 <- 100*abs(EEMC2/colMeans(chain2$THETA))
round(summary(CVMC2), 4)
```

```{r, echo = F, fig.width=4, fig.height=4, fig.align='center'}
# errores estándar de MC 
col <- RColorBrewer::brewer.pal(9,"Set1")[1:9]
par(mfrow = c(1,1), mar = c(2.75,2.75,1.5,0.5), mgp = c(1.7,0.7,0))
boxplot(EEMC1, EEMC2, outline = F, xlim = c(0,3), ylim = range(EEMC1,EEMC2), col = 0, border = c(col[2],col[1]), boxwex = 0.4, main = "Errores Estándar de MC")
axis(side = 1, at = 1:2, labels = c("Modelo 1","Modelo 2"),  cex.axis = 0.8)
lines(x = jitter(x = rep(1,length(EEMC1)), amount = .1), y = EEMC1, type = "p", pch = 20, col = adjustcolor(col[2], 0.3), cex = 1.3)
lines(x = jitter(x = rep(2,length(EEMC2)), amount = .1), y = EEMC2, type = "p", pch = 20, col = adjustcolor(col[1], 0.3), cex = 1.3)
legend("topleft", legend = c("Modelo 1","Modelo 2"), col = col[2:1], fill = col[2:1], border = col[2:1], bty = "n")
```

## Inferencia

```{r, echo = F, fig.width=7, fig.height=7, fig.align='center'}
# gráficos
col <- RColorBrewer::brewer.pal(9,"Set1")[1:9]
par(mfrow = c(2,2), mar = c(2.75,2.75,2.0,0.5), mgp = c(1.7,0.7,0))
# posterior mu
plot (density(chain1$THETA$mu), col = col[1], xlab=expression(mu), ylab = "Densidad", main = expression(mu))
lines(density(chain1$THETA$mu), col = col[1])
lines(density(chain2$THETA$mu), col = col[2])
# posterior tau^2
plot (density(chain1$THETA$tau2), col = col[1], xlab=expression(tau^2), ylab = "Densidad", main = expression(tau^2))
lines(density(chain1$THETA$tau2), col = col[1])
lines(density(chain2$THETA$tau2), col = col[2])
legend("topright", legend = c("Modelo 1","Modelo 2"), col = col[2:1], fill = col[2:1], border = col[2:1], bty = "n")
# posterior nu
plot (1:30, as.numeric(table(factor(x = chain2$THETA$nu, levels = 1:50)))[1:30]/10000, type = "h", lwd = 2, col = col[1], xlab = expression(nu), ylab = "Densidad", main = expression(nu))
abline(h = 0, col = "lightgray")
# posterior sigma^2
plot (density(chain2$THETA$ups2), col = col[1], xlab = expression(sigma^2), ylab = "Densidad", main = expression(sigma^2))
```

```{r, echo = F, fig.width=4, fig.height=4, fig.align='center'}
# medias posteriores Modelo 2 vs. Modelo 1
theta_hat1 <- colMeans(chain1$THETA[,1:m])
theta_hat2 <- colMeans(chain2$THETA[,1:m])
ic1 <- apply(X = chain1$THETA[,1:m], MARGIN = 2, FUN = function(x) quantile(x, c(0.025,0.975)))
ic2 <- apply(X = chain2$THETA[,1:m], MARGIN = 2, FUN = function(x) quantile(x, c(0.025,0.975)))
rango <- range(ic1, ic2)
col <- RColorBrewer::brewer.pal(9,"Set1")[1:9]
par(mfrow = c(1,1), mar = c(2.75,2.75,1.5,0.5), mgp = c(1.7,0.7,0))
plot(NA, NA, xlim = rango, ylim = rango, xlab = "Medias Modelo 1", ylab = "Medias Modelo 2", main = expression(italic("Comparación de medias")))
abline(a = 0, b = 1, lty = 2, col = 1)
lines(theta_hat1, theta_hat2, type = "p", pch = 16, cex = 0.8, col = adjustcolor(1, 0.6))
segments(ic1[1,], theta_hat2, ic1[2,], theta_hat2, col = col[2])
segments(theta_hat1, ic2[1,], theta_hat1, ic2[2,], col = col[1])
legend("bottomright", legend = c("Modelo 1","Modelo 2"), fill = col[2:1], border = col[2:1], bty = "n")
```


# Referencias {-}

```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Hoffcoverbook.jpg")
```

```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Gelmancoverbook.png")
```