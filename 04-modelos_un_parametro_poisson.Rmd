---
title: "Modelo Poisson"
author: 
- Juan Sosa PhD
- Email   jcsosam@unal.edu.co
- GitHub  https://github.com/jstats1702 
date: ""
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Ejemplo de motivación

La base de datos contiene la información de una **muestra aleatoria simple de personas** que residen en hogares particulares o personas que residen en lugares especiales de alojamiento con las características correspondientes al censo.

¿Existen diferencias significativas entre las tasas promedio del **número de hijos** de mujeres de 40 a 44 años con educación superior y sin educación superior?

**Censo Nacional de Población y Vivienda - CNPV - 2018** está disponible en este [enlace](https://microdatos.dane.gov.co/index.php/catalog/643/study-description). 

Diccionario de datos (`ddi-documentation-spanish-643.pdf`) está disponible en este [enlace](https://microdatos.dane.gov.co/index.php/catalog/643/datafile/F11).


# Modelo

El modelo para **variables de conteo** $y_i\in \mathbb{N}_0$, para $i = 1,\ldots,n$, está dado por
$$
\begin{align}
	y_i\mid\theta &\stackrel{\text{iid}}{\sim}\textsf{Poisson}(\theta) \\
	\theta &\sim p(\theta)
\end{align}
$$
donde $\theta\in \Theta = \mathbb{R}^+$.

Este modelo es potencialmente **restrictivo** por la **relación media-varianza**: $\textsf{E}(y_i\mid\theta) = \textsf{Var}(y_i\mid\theta) = \theta$. 

Alternativas: 

- Distribución Binomial Negativa (sobre-dispersión, varianza superior a la esperada).
- Distribución Comway-Maxwell-Poisson (sub-dispersión, varianza menor a la esperada).

La **distribución muestral** (distribución condicional conjunta) de $\boldsymbol{y} = (y_1,\ldots,y_n)$ dado $\theta$ es
$$
  p(\boldsymbol{y}\mid\theta) = \prod_{i=1}^n \frac{\theta^{y_i}\,e^{-\theta}}{y_i!} = \frac{1}{\prod_{i=1}^n y_i!}\,\theta^{s}e^{-n\theta}\,,\quad  s= \textstyle\sum_{i=1}^n y_i\,,
$$
lo cual sugiere que $s$ es un **estadístico suficiente** para $\theta$.

Dado que las $y_i$'s son condicionalmente i.i.d. dado $\theta$ y $s$ es un estadístico suficiente para $\theta$, entonces se tiene el modelo equivalente
$$
\begin{align*}
	s\mid\theta &\sim \textsf{Poisson}(n\theta) \\
	\theta &\sim p(\theta) 
\end{align*}
$$
donde$s\in\mathcal{Y} = \mathbb{N}_0$.


# Modelo Gamma-Poisson

La familia de distribuciones **Gamma** es **conjugada** para la distribución muestral **Poisson**.

Así, el **modelo Gamma-Poisson** es
$$
\begin{align*}
	s\mid\theta&\stackrel{\text{iid}}{\sim}\textsf{Poisson}(n\theta) \\
	\theta &\sim \textsf{Gamma}(a,b)
\end{align*}
$$
donde $a$ y $b$ son los **hiperparámetros** del modelo. 

### Distribución posterior {-}

Bajo el **modelo Gamma-Poisson** se tiene que la **distribución posterior** de $\theta$ es
$$
\theta \mid s \sim \textsf{Gamma}(\theta\mid a + s, b+n)\,.
$$

### Distribución marginal {-}

La **distribución marginal** de $s$ es 
$$
p(s) = \frac{\Gamma(a+n)}{\Gamma(a)\,\Gamma(s+1)}\left( \frac{b}{b+1}\right)^a\left(\frac{1}{b+1}\right)^s\,,\quad s\in\mathbb{N}_0\,.
$$

Esta distribución se conoce como **distribución Gamma Poisson** con parámetros $n\in\mathbb{N}$, $a>0$ y $b>0$, lo que se denota con $y\sim\textsf{Gamma-Poisson}(n,a,b)$.

### Media posterior {-}

La **media posterior** es
$$
        \textsf{E}(\theta\mid s) = \frac{a+s}{b+n} = \frac{b}{b+n}\cdot \frac{a}{b}+\frac{n}{b+n}\cdot \frac{s}{n}\,,
$$
la cual es un **promedio ponderado** de la media previa $\textsf{E}(\theta) = \frac{a}{a+b}$ y la media muestral $\bar{y} = \frac{s}{n}$ con pesos proporcionales a $b$ y $n$, respectivamente. 

- Tal observación conlleva a la siguiente interpretación de los hiperparámetros: 
    - $b$ = número previo de observaciones.
    - $a$ = suma de los conteos asociados con las $b$ observaciones previas.
- Si $n>>b$, entonces la mayoría de la información proviene de los datos en lugar de la información previa.

### Predicción {-}

La **distribución predictiva posterior** de una observación futura $y^*\in\mathbb{N}_0$ es
$$
y^*\mid s \sim \textsf{BN}(a+s,b+n)
\quad\Longleftrightarrow\quad
p(y^*\mid s) = \frac{\Gamma(y^* +a+s)}{\Gamma(a+s)\Gamma(y^*+1)}\left[\frac{b+n}{b+n+1}\right]^{a+s} \left[\frac{1}{b+n+1}\right]^{y^*}\,.
$$

**(Definición.)** La variable aleatoria $X$ tiene distribución **Binomial Negativa** con parámetros $\alpha,\beta > 0$, i.e., $X\sim\textsf{BN}(\alpha,\beta)$, si su función de masa de probabilidad es
$$
p(x) = \frac{\Gamma(x+\alpha)}{\Gamma(\alpha)\,\Gamma(x+1)}\,\left[\frac{\beta}{\beta+1}\right]^{\alpha}\,\left[\frac{1}{\beta+1}\right]^x\,,\quad x\in\mathbb{N}_0\,.
$$

$\theta$ (el objetivo inferencial) y $y^*$ (el objetivo predictivo) tienen la misma media posterior, pero la varianza posterior de $y^*$ es mayor:
$$
\textsf{E}(\theta\mid\boldsymbol{y}) = \textsf{E}(y^*\mid\boldsymbol{y}) = \frac{a+s}{b+n}\,,
$$
mientras que 
$$
\textsf{Var}(\theta\mid\boldsymbol{y}) = \frac{a+s}{b+n}\left(0 + \frac{1}{b+n}\right)
\qquad\text{y}\qquad
\textsf{Var}(y^*\mid\boldsymbol{y}) = \frac{a+s}{b+n}\left(1 + \frac{1}{b+n}\right)\,.
$$


# Ejemplo: Número de hijos y educación

**Censo Nacional de Población y Vivienda - CNPV - 2018** está disponible en este [enlace](https://microdatos.dane.gov.co/index.php/catalog/643/study-description). 

Diccionario de datos (`ddi-documentation-spanish-643.pdf`) está disponible en este [enlace](https://microdatos.dane.gov.co/index.php/catalog/643/datafile/F11).

La base de datos contiene la información de una **muestra aleatoria simple de personas** que residen en hogares particulares o personas que residen en lugares especiales de alojamiento con las características correspondientes al censo.

¿Existen diferencias significativas entre las tasas promedio del **número de hijos** de mujeres de 40 a 44 años con educación superior y sin educación superior?

## Tratamiento de datos {-}

Se consideran personas identificadas como: mujer, jefe de hogar, 40 a 44 años, alfabeta, lugar de nacimiento en Colombia, lugar de residencia hace 5 años en Colombia, ningún grupo étnico, informa si tiene hijos o no.

```{r}
# datos 
df <- read.csv("CNPV2018.txt")
dim(df)
```
`P_NIVEL_ANOSR`: Nivel educativo más alto alcanzado y último año o grado aprobado en ese nivel.
   
- 1: Preescolar.
- 2: Básica primaria.
- 3: Básica secundaria.
- 4: Media académica o clásica.
- 5: Media técnica.
- 6: Normalista.
- 7: Técnica profesional o tecnológica.
- 8: Universitario.
- 9: Especialización, maestría, doctorado.
- 10: Ninguno.
- 99: No Informa.

```{r}
# codificación: nivel educativo
df[df$P_NIVEL_ANOSR %in% c(1,2,3,4,5,6,7,10), c("P_NIVEL_ANOSR")] <- 0 # sin educación superior
df[df$P_NIVEL_ANOSR %in% c(8,9),              c("P_NIVEL_ANOSR")] <- 1 # con educación superior
df$P_NIVEL_ANOSR <- as.numeric(df$P_NIVEL_ANOSR)
```


```{r}
# frecuencias: indicadora de educación superior
table(df$P_NIVEL_ANOSR)
```


`PA1_THNV`: Hijos(as) nacidos vivos.


```{r}
# codificación: sin hijos
df[is.na(df$PA1_THNV), c("PA1_THNV")] <- 0
df$PA1_THNV <- as.numeric(df$PA1_THNV)
```


```{r}
# frecuencias: número de hijos
table(df$PA1_THNV)
```


```{r}
# remover datos faltantes
df <- df[(df$P_NIVEL_ANOSR != 99) & (df$PA1_THNV != 99),]
```


```{r}
# filtro
indices <- (df$P_PARENTESCOR == 1) & (df$P_SEXO == 2) & (df$P_EDADR == 9) & (df$PA1_GRP_ETNIC == 6) & (df$PA_LUG_NAC %in% c(2,3)) & (df$PA_VIVIA_5ANOS %in% c(2,3)) & (df$PA_HNV %in% c(1,2)) & (df$P_ALFABETA == 1)
# y1: número de hijos, mujeres de 40 años, sin educación superior
# y2: número de hijos, mujeres de 40 años, con educación superior
y1 <- as.numeric(df[indices & (df$P_NIVEL_ANOSR == 0), c("PA1_THNV")])
y2 <- as.numeric(df[indices & (df$P_NIVEL_ANOSR == 1), c("PA1_THNV")])
```


```{r}
# tamaños de muestra
(n1 <- length(y1))
(n2 <- length(y2))
# estadísticos suficientes
(s1 <- sum(y1))
(s2 <- sum(y2))
```


```{r, echo = F, fig.height = 5, fig.width = 5, fig.align='center'}
# distribución de frecuencias
par(mfrow = c(1,1), mar = c(3,3,1.4,1.4), mgp = c(1.75,0.75,0))
y <- 0:6
plot(y - .07, table(factor(x = y1, levels = y))/n1, col = 2, type = "h", ylim = c(0,.4), lwd = 3, ylab = "F. Relativa", xlab = "No. de hijos", main = "", yaxt = "n")
points(y + .07, table(factor(x = y2, levels = y))/n2, col = 4, type = "h", lwd = 3)
axis(side = 2)
legend("topright", legend = c("Sin superior", "Con superior"), bty = "n", lwd = 2, col = c(2,4))
```


## Distribuciones posterior y predictiva posterior


```{r}
# previa Gamma(2,1)
a <- 2
b <- 1
# media previa de theta
a/b
# CV previo de theta
sqrt(a/b^2)/(a/b)
# parámetros de la distribución posterior de theta
(ap1 <- a + s1)
(bp1 <- b + n1)
(ap2 <- a + s2)
(bp2 <- b + n2)
```


```{r, echo=F, fig.height = 5, fig.width = 10, fig.align='center'}
# gráfico
par(mfrow = c(1,2), mar = c(3,3,1.4,1.4), mgp = c(1.75,0.75,0))
# posterior
theta <- seq(0, 5, length = 1000)
plot(NA, NA, xlim = c(0,4), ylim = c(0,5.5), xlab = expression(theta), ylab = expression(paste("p","(",theta," | ",y,")",sep="")), main = "Posterior")
lines(theta, dgamma(theta, shape = ap1, rate = bp1), col = 2, lwd = 2)
lines(theta, dgamma(theta, shape = ap2, rate = bp2), col = 4, lwd = 2)
lines(theta, dgamma(theta, shape = a  , rate = b  ), col = 1, lwd = 1)
abline(h = 0, col = 1)
legend("topright", legend = c("Sin superior", "Con superior", "Previa"), bty = "n", lwd = 2, col = c(2, 4, 1))
# predictiva
y <- 0:12
plot(y - .07, dnbinom(y, size = ap1, mu = ap1/bp1), col = 2, type = "h", ylim = c(0,.4), lwd = 3, ylab = "p(y* | y )", xlab = "y*", main = "Predictiva posterior")
points(y + .07, dnbinom(y, size = ap2, mu = ap2/bp2), col = 4, type = "h", lwd = 3)
```


```{r, echo = FALSE}
# media posterior de theta
theta_hat_1 <- ap1/bp1
theta_hat_2 <- ap2/bp2 
# CV posterior de eta
cv_1 <- sqrt(ap1/bp1^2)/(ap1/bp1)
cv_2 <- sqrt(ap2/bp2^2)/(ap2/bp2)
# intervalo de credibilidad al 95% para theta
ic95_1 <- qgamma(p = c(.025,.975), shape = ap1, rate = bp1)
ic95_2 <- qgamma(p = c(.025,.975), shape = ap2, rate = bp2)
# probabilidad posterior de theta > 2
pr_theta_1 <- pgamma(q = 2, shape = ap1, rate = bp1, lower.tail = F)
pr_theta_2 <- pgamma(q = 2, shape = ap2, rate = bp2, lower.tail = F)
# probabilidad posterior de y* > 2
pr_y_1 <- pnbinom(q = 2, size = ap1, mu = ap1/bp1, lower.tail = F)
pr_y_2 <- pnbinom(q = 2, size = ap2, mu = ap2/bp2, lower.tail = F)
# tabla
tab <- cbind(c(theta_hat_1, cv_1, ic95_1, pr_theta_1, pr_y_1),
             c(theta_hat_2, cv_2, ic95_2, pr_theta_2, pr_y_2))
colnames(tab) <- c("Sin superior", "Con superior")
rownames(tab) <- c("Media tasa", "CV tasa", "Q2.5% tasa", "Q97.5% tasa", "Pr. tasa > 2", "Pr. pred. > 2")
knitr::kable(x = t(tab), digits = 3, align = "c", caption = "Inferencia sobre la tasa del número de hijos.")
```


## Comparación de grupos


```{r}
set.seed(123)
# muestras de la distribución posterior de theta
th1_mc <- rgamma(n = 10000, shape = ap1, rate = bp1)
th2_mc <- rgamma(n = 10000, shape = ap2, rate = bp2)
# muestras de la distribución predictiva posterior
y1_mc <- rpois(n = 10000, lambda = th1_mc)
y2_mc <- rpois(n = 10000, lambda = th2_mc)
```


```{r}
# muestras de la distribución posterior de eta = theta_1 - theta_2
eta <- th1_mc - th2_mc
```


```{r, echo = FALSE, fig.height = 5, fig.width = 10, fig.align='center'}
# gráfico
par(mfrow = c(1,2), mar = c(3,3,1.4,1.4), mgp = c(1.75,0.75,0))
# posterior
theta <- seq(0, 5, length = 1000)
hist(x = eta, freq = F, col = "gold2", border = "gold2", xlab = expression(eta), ylab = expression(paste("p","(",eta," | ",y,")",sep="")), main = "Posterior")
plot(x = density(eta), col = "gold3", lwd = 2, xlab = expression(eta), ylab = expression(paste("p","(",eta," | ",y,")",sep="")), main = "Posterior")
```


```{r}
# media posterior de eta = theta_1 - theta_2
mean(eta)
# CV posterior de eta = theta_1 - theta_2
sd(eta)/mean(eta)
# intervalos de credibilidad al 95% para eta = theta_1 - theta_2
quantile(x = eta, probs = c(.025,.975))
```


```{r, echo=F}
# inferencia Bayesiana
est_B <- mean(eta)
cv_B  <- sd(eta)/mean(eta)
ic_B  <- quantile(x = eta, probs = c(.025,.975))
# inferencia frecuentista: asintótica
yb1 <- mean(y1)
yb2 <- mean(y2)
sd1 <- sd(y1)
sd2 <- sd(y2)
est_F1 <- yb1 - yb2
cv_F1  <- sqrt(sd1^2/n1 + sd2^2/n2)/(yb1 - yb2)
ic_F1  <- yb1 - yb2 + c(-1,1)*qnorm(p = 0.975)*sqrt(sd1^2/n1 + sd2^2/n2)
# inferencia frecuentista: bootstrap paramétrico
out <- NULL
set.seed(123)
for (i in 1:10000) {
  yy1 <- rpois(n = n1, lambda = yb1)
  yy2 <- rpois(n = n2, lambda = yb2)
  out[i] <- mean(yy1) - mean(yy2)
}
est_F2 <- mean(out)
cv_F2  <- sd(out)/mean(out)
ic_F2  <- quantile(x = out, probs = c(.025,.975))
# inferencia frecuentista: bootstrap no paramétrico
out <- NULL
set.seed(123)
for (i in 1:10000) {
  yy1 <- sample(x = y1, size = n1, replace = T)
  yy2 <- sample(x = y2, size = n2, replace = T)
  out[i] <- mean(yy1) - mean(yy2)
}
est_F3 <- mean(out)
cv_F3  <- sd(out)/mean(out)
ic_F3  <- quantile(x = out, probs = c(.025,.975))
```


```{r, echo=F}
# resultados
tab <- rbind(c(est_B , cv_B , ic_B ), 
             c(est_F1, cv_F1, ic_F1), 
             c(est_F2, cv_F2, ic_F2),
             c(est_F3, cv_F3, ic_F3))
colnames(tab) <- c("Estimación", "CV", "L. Inf.", "L. Sup.")
rownames(tab) <- c("Bayesiana", "Frec. Asintótico", "Frec. Bootstrap Par.", "Frec. Bootstrap No Par.")
knitr::kable(x = tab, digits = 3, align = "c", caption = "Inferencia sobre la diferencia entre las tasas promedio del número de hijos de mujeres de 40 a 44 años con educación superior y sin educación superior.")
```


# Ejemplo: Número de hijos y educación (cont.)


```{r, echo = F}
# filtro
indices <- (df$P_PARENTESCOR == 1) & (df$P_SEXO == 2) & (df$PA1_GRP_ETNIC == 6) & (df$PA_LUG_NAC %in% c(2,3)) & (df$PA_VIVIA_5ANOS %in% c(2,3)) & (df$PA_HNV %in% c(1,2)) & (df$P_ALFABETA == 1)
# previa Gamma(2,1)
a <- 2
b <- 1
# P_EDADR: Edad en Grupos Quinquenales
#   1 de 00 A 04 Años
#   2 de 05 A 09 Años
#   3 de 10 A 14 Años
#   4 de 15 A 19 Años
#   5 de 20 A 24 Años
#   6 de 25 A 29 Años
#   7 de 30 A 34 Años
#   8 de 35 A 39 Años
#   9 de 40 A 44 Años
#   10 de 45 A 49 Años
#   11 de 50 A 54 Años
#   12 de 55 A 59 Años
#   13 de 60 A 64 Años
#   14 de 65 A 69 Años
#   15 de 70 A 74 Años
#   16 de 75 A 79 Años
#   17 de 80 A 84 Años
#   18 de 85 A 89 Años
#   19 de 90 A 94 Años
#   20 de 95 A 99 Años
#   21 de 100 y más Años
out <- NULL
set.seed(1234)
for (k in 5:14) {
  # datos
  y1 <- as.numeric(df[indices & (df$P_EDADR == k) & (df$P_NIVEL_ANOSR == 0), c("PA1_THNV")])
  y2 <- as.numeric(df[indices & (df$P_EDADR == k) & (df$P_NIVEL_ANOSR == 1), c("PA1_THNV")])
  # tamaños de muestra
  n1 <- length(y1)
  n2 <- length(y2)
  # estadísticos suficientes
  s1 <- sum(y1)
  s2 <- sum(y2)
  # parámetros de la posterior
  ap1 <- a + s1
  bp1 <- b + n1
  ap2 <- a + s2
  bp2 <- b + n2
  # muestras distribución posterior
  th1_mc <- rgamma(n = 10000, shape = ap1, rate = bp1)
  th2_mc <- rgamma(n = 10000, shape = ap2, rate = bp2)
  # inferencia Bayesiana
  est  <- mean(th1_mc - th2_mc)
  cv   <- sd(th1_mc - th2_mc)/mean(th1_mc - th2_mc)
  ic95 <- quantile(x = th1_mc - th2_mc, probs = c(.025,.975))
  ic99 <- quantile(x = th1_mc - th2_mc, probs = c(.005,.995))
  # output
  out <- rbind(out, c(est, cv, ic95, ic99))
}
colnames(out) <- c("Estimación","CV","Q2.5%","Q97.5%","Q0.5%","Q99.5%")
rownames(out) <- paste0(seq(from = 20, to = 65, by = 5), "-", seq(from = 24, to = 69, by = 5))
knitr::kable(x = out[,1:4], digits = 3, align = "c", caption = "Inferencia sobre la diferencia entre las tasas promedio del número de hijos con educación superior y sin educación superior, por grupos quinqueniales de edad.")
```


```{r, echo=F, fig.align='center'}
plot(x = 1:nrow(out), y = out[,1], ylim = c(0,2), pch = 16, cex = 1, xaxt = "n", xlab = "Edad en Grupos Quinquenales", ylab = expression(theta[1]-theta[2]))
lines(x = 1:nrow(out), y = out[,1], type = "l", col = 4)
abline(h = 0, col = 1, lty = 2)
abline(v = 1:nrow(out), col = "gray95")
segments(x0 = 1:nrow(out), y0 = out[,3], x1 = 1:nrow(out), y1 = out[,4], lwd = 3)
segments(x0 = 1:nrow(out), y0 = out[,5], x1 = 1:nrow(out), y1 = out[,6], lwd = 1)
axis(side = 1, at = 1:nrow(out), labels = rownames(out), las = 1)
```


```{r, echo=F, fig.align='center'}
plot(x = 1:nrow(out), y = out[,2], ylim = c(0,0.25), pch = 20, cex = 1, xaxt = "n", xlab = "Edad en Grupos Quinquenales", ylab = "Coef. Variación")
axis(side = 1, at = 1:nrow(out), labels = rownames(out), las = 1)
abline(v = 1:nrow(out), col = "gray95")
abline(h = 0.05, lty = 2, col = 3)
abline(h = 0.10, lty = 2, col = "#FFA500")
abline(h = 0.15, lty = 2, col = 2)
lines(x = 1:nrow(out), y = out[,2], type = "l", col = 4)
lines(x = 1:nrow(out), y = out[,2], type = "p", pch = 20, cex = 1.1)
```


# Referencias {-}


```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Hoffcoverbook.jpg")
```


```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Gelmancoverbook.png")
```