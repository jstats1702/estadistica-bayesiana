---
title: "Muestreador de Gibbs"
author: 
- Juan Sosa PhD
- Email   jcsosam@unal.edu.co
- GitHub  https://github.com/jstats1702 
date: ""
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ejemplo de motivación

La base de datos contiene la información de una **muestra aleatoria simple** de los **estudiantes que presentaron la Prueba Saber 11 en 2023-2**. 

La **prueba de matemáticas** está diseñada con una **escala de 0 a 100** (sin decimales), un **puntaje promedio de 50** y una **desviación estándar de 10 puntos**.

¿Existe suficiente evidencia para concluir que el puntaje promedio de Matemáticas de Bogotá es significativamente superior al puntaje promedio preestablecido por la prueba?

¿Qué ocurre en el caso de Vichada?

Los datos son públicos y están disponibles en este [enlace](https://www.icfes.gov.co/data-icfes/). 

# Modelo Normal con distribución previa semi-conjugada

El modelo Normal para **variables continuas** $y_i\in \mathbb{R}$, para $i = 1,\ldots,n$, está dado por
$$
\begin{align*}
	y_i\mid\theta,\sigma^2 &\stackrel{\text{iid}}{\sim} \textsf{N}(\theta,\sigma^2)\\
	(\theta,\sigma^2) &\sim p(\theta,\sigma^2) 
\end{align*}
$$

Considere especificar el estado de información previo acerca de $\theta$ de manera **independiente** de $\sigma^2$ de forma que
$p(\theta,\sigma^2) = p(\theta)\,p(\sigma^2)$, donde
$$
\theta   \sim \textsf{N}(\mu_0, \tau^2_0)
\qquad\text{y}\qquad
\sigma^2 \sim \textsf{GI}\left(\tfrac{\nu_0}{2},\tfrac{\nu_0\,\sigma^2_0}{2}\right)\,,
$$
y $\mu_0$, $\tau^2_0$, $\nu_0$, $\sigma^2_0$ son los **hiperparámetros** del modelo.

Esta formulación es **flexible** porque **no hay una restricción de dependencia a priori** entre $\theta$ y $\sigma^2$.

En el caso de la previa conjugada (donde $\tau_0^2$ es proporcional a $\sigma^2$) se tiene que la distribución posterior de $\sigma^2$ es Gamma Inversa. En este caso, **la distribución posterior de $\sigma^2$ no sigue una distribución estándar conocida**.

# Muetreador de Gibbs

El **muestreador de Gibbs** (*Gibbs sampler*) es un algoritmo que permite **obtener muestras dependientes** de la **distribución posterior** por medio de las **distribuciones condicionales completas** de los parámetros.

Dado un **estado actual** de los parámetros del modelo $\boldsymbol{\theta}^{(b)} = \left(\theta^{(b)}, \sigma^{2\,(b)}\right)$, se genera un nuevo estado $\boldsymbol{\theta}^{(b+1)}= \left(\theta^{(b+1)}, \sigma^{2\,(b+1)}\right)$ como sigue:

1. Muestrear $\theta^{(b+1)}\sim p(\theta\mid\sigma^{2\,(b)}, \boldsymbol{y})$.
2. Muestrear $\sigma^{2\,(b+1)}\sim p(\sigma^2\mid\theta^{(b+1)}, \boldsymbol{y})$.
3. Establecer $\boldsymbol{\theta}^{(b+1)} = \left(\theta^{(b+1)}, \sigma^{2\,(b+1)}\right)$. 
4. Repetir los pasos 1. a 3. hasta convergencia.

El **muestreador de Gibbs** genera una **cadena de Markov** (*Markov chain*) $\boldsymbol{\theta}^{(1)},\ldots,\boldsymbol{\theta}^{(B)}$, dado que $\boldsymbol{\theta}^{(b+1)}$ depende únicamente de $\boldsymbol{\theta}^{(b)}$.

La **distribución estacionaria** de la cadena $\boldsymbol{\theta}^{(1)},\ldots,\boldsymbol{\theta}^{(B)}$ corresponde a la **distribución posterior** $p(\boldsymbol{\theta}\mid \boldsymbol{y})$.

Smith, A. F. M., & Roberts, G. O. (1993). Bayesian computation via the Gibbs sampler and related Markov chain Monte Carlo methods. *Journal of the Royal Statistical Society: Series B (Methodological)*, *55*(1), 3–23.

## Distribuciones condicionales completas

Bajo el **modelo Normal con distribución previa semi-conjugada**, se tiene que:

- La **distribución condicional completa** de $\theta$ es $\theta\mid\sigma^2,\boldsymbol{y}\sim\textsf{N}(\mu_n,\tau^2_n)$, donde
$$
\mu_n = \frac{\frac{1}{\tau^2_0}\mu_0 + \frac{n}{\sigma^2}\bar{y}}{\frac{1}{\tau^2_0} + \frac{n}{\sigma^2}} \qquad\text{y}\qquad\tau^2_n=\frac{1}{\frac{1}{\tau^2_0} + \frac{n}{\sigma^2}}\,.
$$
- La **distribución condicional completa** de $\sigma^2$ es $\sigma^2\mid\theta,\boldsymbol{y}\sim\textsf{GI}\left(\tfrac{\nu_n}{2},\tfrac{\nu_n\,\sigma^2_n}{2}\right)$, donde
$$
\nu_n = \nu_0+n\qquad\text{y}\qquad \nu_n\sigma^2_n = \nu_0\sigma^2_0 + ns^2_\theta\,,
$$
con $s^2_\theta = \tfrac{1}{n}\sum_{i=1}^n (y_i-\theta)^2$, lo que corresponde a un estimador insesgado de $\sigma^2$ si $\theta$ fuera conocido. 

Como punto de partida, solo es necesario proporcionar un valor inicial para $\sigma^2$. Usualmente este valor se muestrea de la distribución previa, esto es, $\sigma^{2\,(0)}\sim\textsf{IG}\left(\tfrac{\nu_0}{2},\tfrac{\nu_0\,\sigma^2_0}{2}\right)$.

# Ejemplo: Puntajes de Matemáticas

La base de datos contiene la información de una **muestra aleatoria simple** de los **estudiantes que presentaron la Prueba Saber 11 en 2023-2**. 

La **prueba de matemáticas** está diseñada con una **escala de 0 a 100** (sin decimales), un **puntaje promedio de 50** y una **desviación estándar de 10 puntos**.

¿Existe suficiente evidencia para concluir que el puntaje promedio de Matemáticas de Bogotá es significativamente superior al puntaje promedio preestablecido por la prueba?

¿Qué ocurre en el caso de Vichada?

Los datos son públicos y están disponibles en este [enlace](https://www.icfes.gov.co/data-icfes/). 

## Tratamiento de datos {-}

```{r}
# datos
dat <- read.csv("C:/Users/User/Dropbox/UN/estadistica_bayesiana/SB11_20232_muestra.txt", sep=";")
# dimensión de la base
dim(dat)
# distribución de frecuencias
table(dat$ESTU_DEPTO_RESIDE)
```

```{r}
# datos Bogotá
y <- dat[dat$ESTU_COD_RESIDE_DEPTO == 11, "PUNT_MATEMATICAS"]
# tamaño de la muestra
(n <- length(y))
# estadísticos suficientes
(mean_y <- mean(y))
(var_y  <- var(y))
```

## Muestreador de Gibbs {-}

```{r}
# hiperparámetros
mu0 <- 50  
t20 <- 10^2 # regla empírica: P( |\theta - \mu_0| < 3\tau_0 ) = 99.7%
s20 <- 10^2 
nu0 <- 1
```

```{r}
# número de muestras 
B <- 100000
# mostrar anuncios cada 10% de las iteraciones
ncat <- floor(B/10) 
# matriz para almacenar las muestras
THETA <- matrix(data = NA, nrow = B, ncol = 2)
colnames(THETA) <- c("theta", "sig2")
```

```{r}
# algoritmo: muestreador de Gibbs
# inicializar
set.seed(123)
sig2 <- 1/rgamma(n = 1, shape = nu0/2, rate = nu0*s20/2)
# cadena
for(b in 1:B) {
  # actualizar \theta
  t2n   <- 1/(1/t20 + n/sig2)      
  mun   <- t2n*(mu0/t20 + n*mean_y/sig2)
  theta <- rnorm(n = 1, mean = mun, sd = sqrt(t2n))
  # actualizar \sigma^2
  nun  <- nu0 + n
  s2n  <- (nu0*s20 + sum((y - theta)^2))/nun
  sig2 <- 1/rgamma(n = 1, shape = nun/2, rate = nun*s2n/2)
  # almacenar
  THETA[b,] <- c(theta, sig2)
  # progreso
  if (b%%ncat == 0) 
    cat(100*round(b/B, 1), "% completado ... \n", sep = "")
}
```

```{r, echo=F, fig.width = 8, fig.height = 4, fig.align = 'center'}
# visualización del algoritmo: no se hace en la practica
par(mfrow = c(1,2), mar = c(2.75,3,0.5,0.5), mgp = c(1.7,0.7,0))
m1 <- 15
plot(THETA[1:m1,], type = "l", xlim = range(THETA[1:100,1]), ylim = range(THETA[1:100,2]), lty = 1, col="gray", xlab = expression(theta), ylab = expression(sigma^2))
text(x = THETA[1:m1,1], y = THETA[1:m1,2], labels = c(1:m1))
m1 <- 100
plot(THETA[1:m1,], type = "l", xlim = range(THETA[1:100,1]), ylim = range(THETA[1:100,2]), lty = 1, col="gray", xlab = expression(theta), ylab = expression(sigma^2))
text(x = THETA[1:m1,1], y = THETA[1:m1,2], labels = c(1:m1))
```

## Distribuciones posterior y marginales {-}

```{r, echo=FALSE, fig.width=6, fig.height=6, fig.align='center'}
# distribución conjunta
plot(THETA[,1], THETA[,2], pch = ".", xlim = range(THETA[,1]), ylim = range(THETA[,2]), xlab = expression(theta), ylab = expression(sigma^2))
```

```{r, echo=FALSE, fig.width=8, fig.height=4, fig.align='center'}
par(mfrow = c(1,2), mar = c(2.75,3,0.5,0.5), mgp = c(1.7,0.7,0))
# media
plot(density(THETA[,1]), xlab = expression(theta), main = "", xlim = range(THETA[,1]), ylab = "Densidad")
# varianza
plot(density(THETA[,2]), xlab = expression(sigma^2), main = "", xlim = range(THETA[,2]), ylab = "Densidad") 
```

## Inferencia {-}

```{r}
# media
round(quantile(THETA[,1], c(.025, 0.5, 0.975)), 3)
# desviación estándar
round(quantile(sqrt(THETA[,2]), c(.025, 0.5, 0.975)), 3)
# coeficiente de variación
round(quantile(100*abs(sqrt(THETA[,2])/THETA[,1]), c(.025, 0.5, 0.975)), 3)
```
## Convergencia {-}

```{r, fig.width=8, fig.height=8, fig.align='center'}
# cadenas
par(mfrow = c(2,1), mar = c(3,3,1,1), mgp = c(1.75,0.75,0))
plot(THETA[-c(1:10),1], type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta))
plot(THETA[-c(1:10),2], type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma^2))
```


# Algoritmo general

Dado un **estado actual** $\boldsymbol{\theta}^{(b)} = \left(\theta_1^{(b)},\ldots,\theta_k^{(b)}\right)$, se genera un **nuevo estado** $\boldsymbol{\theta}^{(b+1)}$ como sigue:

1. Muestrear $\theta_1^{(b+1)}\sim p\left(\theta_1\mid\theta_2^{(b)},\theta_3^{(b)},\ldots,\theta_k^{(b)}\right)$.
2. Muestrear $\theta_2^{(b+1)}\sim p\left(\theta_2\mid\theta_1^{(b+1)},\theta_3^{(b)},\ldots,\theta_k^{(b)}\right)$.
3. Muestrear $\theta_3^{(b+1)}\sim p\left(\theta_3\mid\theta_1^{(b+1)},\theta_2^{(b+1)},\ldots,\theta_k^{(b)}\right)$.
4. ...
5. Muestrear $\theta_k^{(b+1)}\sim p\left(\theta_k\mid\theta_1^{(b+1)},\theta_2^{(b+1)},\ldots,\theta_{k-1}^{(b+1)}\right)$.
6. Establecer $\boldsymbol{\theta}^{(b+1)} = \left(\theta_1^{(b+1)},\ldots,\theta_k^{(b+1)}\right)$.
7. Repetir los pasos 1. a 6. hasta convergencia.

## Cadenas de Markov

Un **proceso estocástico** es una colección de variables aleatorias $\{\theta_t\in S:t\in T\}$ para algún **espacio de estados** $S$ bien sea **discreto**, e.g., $\{1,\ldots,k\}$, o continuo, e.g., $(-\infty,\infty)$, y un **conjunto de índices** $T$, bien sea **discreto**, e.g., $\{0,1,\ldots\}$), o continuo, e.g., $[0,\infty)$.

Un proceso estocástico $\{\theta_t\in S:t\in T\}$, con $T=\{0,1,\ldots\}$, se denomina **cadena de Markov** si, para todo $A\subset S$, se tiene que
$$
\textsf{Pr}(\theta_{t+1}\in A\mid \theta_0,\ldots,\theta_t) = \textsf{Pr}(\theta_{t+1}\in A\mid\theta_t)\,.
$$

## Cadenas de Markov ergódicas

Una **cadena de Markov ergódica** satisface ciertas propiedades que garantizan su convergencia a un **comportamiento estable a largo plazo** (distribución estacionaria).

Una cadena de Markov es ergódica si satisface las siguientes propiedades:

- **Irreducibilidad:** Para cualquier par de estados $i$ y $j$, existe un número finito de pasos $n$ tal que $\text p^n(i, j) > 0$, donde $\text p^n(i, j)$ es la probabilidad de transición desde $i$ hasta $j$ en $n$ pasos.

- **Aperiodicidad:** Para cada estado $i$, el máximo común divisor de los tiempos de retorno al estado $i$ es 1. Es decir, no hay un período fijo $d > 1$ tal que los estados solo puedan ser visitados en múltiplos de $d$.

- **Recurrente positiva:** Para todo estado $i$, el tiempo esperado de retorno al mismo estado es finito. Es decir, $\textsf{E}[\tau_i] < \infty$, donde $\tau_i$ es el tiempo de retorno al estado $i$.

## Teorema Ergódico

Las **cadenas de Markov ergódicas** poseen una **distribución estacionaria** única $\pi(\theta)$. Esta distribución caracteriza el **comportamiento que adopta la cadena después de evolucionar mucho tiempo**, independientemente de su estado inicial.

**(Teorema Ergódico.)** Si una cadena de Markov $\{\theta_t\in S:t\in T\}$ es **ergódica** y si $f$ es una función de valor real tal que $\textsf{E}_\pi|f(\theta)|<\infty$, entonces, con probabilidad 1, cuando $B\rightarrow\infty$, se tiene que
$$
\frac{1}{B}\sum_{b=1}^B f(\theta_b) \longrightarrow \textsf{E}_{\pi(\theta)}(f(\theta)) = \int_\Theta f(\theta)\,\pi(\theta)\,\textsf{d}\theta
$$
donde el valor esperado de $f(\theta)$ se toma respecto a la **distribución estacionaria** $\pi(\theta)$.

## Resumen

Una **cadena de Markov** construida a partir del **muestreador de Gibbs** es **ergódica** y además tiene como **distribución estacionaria** la **distribución posterior**. 

La secuencia $\boldsymbol{\theta}^{(1)},\ldots,\boldsymbol{\theta}^{(B)}$ se puede usar **como si se tratara de una muestra aleatoria** de valores de $\boldsymbol{\theta}$ provenientes de la distribución posterior $p(\boldsymbol{\theta}\mid y)$. Esto es,
$$
\frac{1}{B} \sum_{b=1}^{B} g(\boldsymbol{\theta}) \longrightarrow \textsf{E}[g(\boldsymbol{\theta}) \mid \boldsymbol{y}]=\int_{\Theta} g(\boldsymbol{\theta})\, p(\boldsymbol{\theta} \mid \boldsymbol{y})\,\textsf{d}\boldsymbol{\theta}\qquad\text{cuando}\qquad B\rightarrow \infty\,.
$$

El **punto de partida** $\boldsymbol{\theta}^{(0)}$ es **arbitrario** y usualmente se genera de la distribución previa.

El **muestreador de Gibbs** hace parte de un conjunto de técnicas de aproximación denominadas **cadenas de Markov de Monte Carlo** (*Markov Chain Monte Carlo*, MCMC).

Los métodos de MCMC constituyen **técnicas de aproximación numérica**, **no son modelos**, y **no generan más información** además de la contenida en $\boldsymbol{y}$.

## Diagnósticos de convergencia

El muestreador de Gibbs produce **muestras que eventualmente van a converger a la distribución posterior**, pero en algunos casos la **convergencia puede ser lenta** debido a la **autocorrelación** de los parámetros.

- ¿Cuál es el punto de partida de la cadena?
- ¿Cuándo la cadena alcanza el equilibrio?
- Una vez alcanzado el equilibrio, ¿cuánto tiempo se debe monitorear la cadena?

No es posible estar absolutamente seguro que la cadena ha convergido. **Solo se puede saber si no lo ha hecho.**

### Serie {-}

Las series permiten chequear **estacionariedad**. 

Para resolver problemas de estacionariedad se recomienda **correr la cadena con más iteraciones**.

```{r, fig.width=8, fig.height=8, fig.align='center'}
# cadenas
par(mfrow = c(2,1), mar = c(3,3,1,1), mgp = c(1.75,0.75,0))
plot(THETA[-c(1:10),1], type = "p", pch = ".", xlab = "Iteración", ylab = expression(theta))
plot(THETA[-c(1:10),2], type = "p", pch = ".", xlab = "Iteración", ylab = expression(sigma^2))
```

```{r, fig.width=8, fig.height=4, fig.align='center'}
# log-verosimilitud
LL <- NULL
for (i in 1:B)
  LL[i] <- sum(dnorm(x = y, mean = THETA[i,1], sd = sqrt(THETA[i,2]), log = T))
# cadena
plot(LL[-c(1:10)], type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud")
```


### Autocorrelación {-}

La función de autocorrelación está dada por
$$
\operatorname{acf}_{t}(\theta)=\frac{\frac{1}{B-t} \sum_{b=1}^{B-t}\left(\theta^{(b)}-\bar{\theta}\right)\left(\theta^{(b+t)}-\bar{\theta}\right)}{\frac{1}{B-1} \sum_{b=1}^{B}\left(\theta^{(b)}-\bar{\theta}\right)^{2}},
\qquad\text{donde}
\qquad\bar{\theta} = \frac{1}{B}\sum_{b=1}^B \theta^{(b)}.
$$

Entre **mayor sea la autocorrelación**, se necesitan **más muestras** para obtener la precisión deseada.

Para resolver problemas de correlación se recomienda:

- **Adelgazar la cadena** (muestreo sistemático de la cadena).
- **Reparametrizar el modelo.**

```{r, fig.width=8, fig.height=4, fig.align='center'}
# autocorrelación
par(mfrow = c(1,2), mar = c(3,3,3,1), mgp = c(1.75,0.75,0))
acf(THETA[,1], main = expression(theta))
acf(THETA[,2], main = expression(sigma^2))
```

### Tamaño efectivo de muestra {-}

Las cadenas suelen estar **autocorrelacionadas** por lo que **contienen menos información que una secuencia de muestras IID** de la distribución posterior.


El **tamaño efectivo de la muestra** es el número de muestras IID que contendrían la misma información de la cadena:
$$
n_{\text{eff}}(\theta) = \frac{B}{1+2\sum_{t=1}^\infty \text{acf}_t(\theta)}\,,
$$
donde $\rho_t$ es la autocorrelación en el lag $t$. Comúnmente, la suma se hace hasta que $\text{acf}_{t-1}+\text{acf}_t < 0$.

```{r}
# tamaño efectivo de la muestra
neff <- coda::effectiveSize(THETA)
round(neff, 0)
```

### Error estándar de Monte Carlo {-}
  
El **error estándar de Monte Carlo** hace referencia a la desviación estándar del promedio muestral respecto al tamaño efectivo de muestra:
$$
\textsf{EMC}(\hat\theta) = \frac{\textsf{DE}(\hat\theta)}{\sqrt{n_{\text{eff}}(\theta)}}\,,
$$
donde $\hat\theta = \frac{1}{B} \sum_{b=1}^B \theta^{(b)}$ es la media posterior, $\textsf{DE}(\hat\theta) = \sqrt{\frac{1}{B-1}\sum_{b=1}^B (\theta^{(b)}-\hat\theta)^2}$ es la desviación estándar posterior, y $n_{\text{eff}}$ es el tamaño efectivo de la muestra.

```{r}
# error estándar de Monte Carlo
EMC <- apply(X = THETA, MARGIN = 2, FUN = sd)/sqrt(neff)
round(EMC, 4)
```

```{r}
# coeficiente de variación de Monte Carlo (%)
CVMC <- 100*abs(EMC/colMeans(THETA))
round(CVMC, 4)
```

### Más diagnósticos {-}

- https://cran.r-project.org/web/packages/bayesplot/vignettes/visual-mcmc-diagnostics.html .
- https://arviz-devs.github.io/arviz/api/diagnostics.html .

# Referencias {-}

```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Hoffcoverbook.jpg")
```

```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Gelmancoverbook.png")
```