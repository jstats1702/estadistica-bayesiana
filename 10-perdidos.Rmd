---
title: "Datos perdidos e imputación"
author: 
- Juan Sosa PhD
- Email   jcsosam@unal.edu.co
- GitHub  https://github.com/jstats1702 
date: ""
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newcommand{\simiid}{\,{\stackrel{\text{iid}}{\sim}}\,}
\newcommand{\simind}{\,{\stackrel{\text{ind}}{\sim}}\,}

\newcommand{\te}{\theta}
\newcommand{\si}{\sigma}

\newcommand{\ov}{\boldsymbol{o}}
\newcommand{\xv}{\boldsymbol{x}}
\newcommand{\yv}{\boldsymbol{y}}
\newcommand{\muv}{\boldsymbol{\mu}}
\newcommand{\tev}{\boldsymbol{\theta}}
\newcommand{\omev}{\boldsymbol{\omega}}
\newcommand{\xiv}{\boldsymbol{\xi}}
\newcommand{\phiv}{\boldsymbol{\phi}}

\newcommand{\Om}{\mathbf{O}}
\newcommand{\Wm}{\mathbf{W}}
\newcommand{\Ym}{\mathbf{Y}}
\newcommand{\Sm}{\mathbf{S}}
\newcommand{\SIG}{\mathbf{\Sigma}}
\newcommand{\LAM}{\mathbf{\Lambda}}

\newcommand{\Nor}{\small{\textsf{N}}}
\newcommand{\Cat}{\small{\textsf{Categorica}}}
\newcommand{\Dir}{\small{\textsf{Dirichlet}}}
\newcommand{\IG} {\small{\textsf{GI}}}


# Introducción

Algunos datos de algunas personas están **perdidos** (*missing*).

Si algunos datos están **perdidos** no es claro cómo hacer la **estimación de los parámetros del modelo**. 

Es una **mala práctica** ajustar el modelo:

- Eliminanado los individuos con datos faltantes.
- Imputando los valores faltantes con la media poblacional o algún otro valor fijo.

Los datos faltantes introducen sesgos en un análisis de los datos completos dependiendo de la **estructura causal del proceso de perdida de datos**.


### Perdidos completamente al azar (MCAR, *missing completely at random*) {-}

La falta de datos es independiente de los datos observados y no observados.

No existen diferencias sistemáticas entre los participantes con datos faltantes y aquellos con datos completos.

Los datos completos se pueden considerar como una muestra aleatoria de la población de interés.


### Perdidos al azar (MCAR, *missing at random*) {-}

La falta de datos está relacionada con los datos observados, pero no con los no observados.

Por ejemplo, en un estudio de depresión, la probabilidad de completar la encuesta puede estar relacionada con el sexo (variable de control completamente observada), pero no con la gravedad de la depresión (variable de interés).

Un manejo adecuado de los factores conocidos puede conducir a resultados imparciales.


### Perdidos no al azar (MCAR, *missing not at random*) {-}

La falta de datos está relacionada con los datos no observados (i.e., con eventos o factores que no son medidos por el investigador).

Continuando con el ejemplo anterior, los participantes con depresión severa tienen más probabilidades de negarse a completar la encuesta sobre la gravedad de la depresión (variable de interés).

Por lo general no es posible llevar a cabo resultados imparciales dado que no se observan factores asociados con la perdida de datos. 




# Modelo Normal Multivariado Semi-Conjugado

- **Distribución muestral**:
$$
\yv_i\mid\tev,\SIG \stackrel{\text{iid}}{\sim} \textsf{N}(\tev,\SIG)\,,\qquad i=1,\ldots,n\,.
$$
donde $\yv_i = (y_{i,1},\ldots,y_{i,p})\in\mathbb{R}^p$.

- **Distribución previa**:
$$
p(\tev,\SIG) = p(\tev)\,p(\SIG) 
$$
donde
$$
\begin{align*}
\tev  &\sim \textsf{N} (\muv_0, \LAM_0) \\
\SIG  &\sim \textsf{WI}(\nu_0,\Sm_0^{-1})
\end{align*}
$$

- **Parámetros**: $\tev$, $\SIG$.

- **Hiperparámetros**: $\muv_0, \LAM_0, \nu_0, \Sm_0$.

La distribución posterior $p(\tev,\SIG\mid\Ym)$ depende directamente de la distribución muestral $p(\Ym\mid\tev,\SIG) = \prod_{i=1}^n p(\yv_i\mid\tev,\SIG)$, con $\mathbf{Y}=[\yv_1^\textsf{T},\ldots,\yv_n^\textsf{T}]^\textsf{T}$, la cual **no se puede calcular si faltan observaciones** en algunas de las $\yv_i$.




# Estimación con datos faltantes al azar

Sea $\ov_i = (o_{i,1},\ldots,o_{i,p})$ un vector con entradas binarias tales que 
$$
o_{i,j} = 
\begin{cases}
1, & \text{si $y_{i,j}$ es un dato observado;} \\
0, & \text{si $y_{i,j}$ es un dato faltante,}
\end{cases}
$$
para $i=1,\ldots,n$ y $j = 1,\ldots,p$. Además, $\Om = [\ov_1^\textsf{T},\ldots,\ov_n^\textsf{T}]^\textsf{T}$.

La matriz $\Ym$ consiste de dos partes, $\Ym = (\Ym_{\text{obs}},\Ym_{\text{miss}})$, donde
$$
\Ym_{\text{obs}}  = \{y_{i,j}: o_{i,j} = 1\}
\qquad\text{y}\qquad
\Ym_{\text{miss}} = \{y_{i,j}: o_{i,j} = 0\}\,.
$$

Similarmente, $\yv_i = (\yv_{i,\text{obs}},\yv_{i,\text{miss}})$, para $i=1,\ldots,n$.

La **información observada** del individuo $i$ es $\ov_i$ y $\yv_{i,\text{obs}}$.

Bajo el supuesto de **datos faltantes al azar**:

- $\Om$ es **independiente** de los parámetros del modelo.
- $\Om$ y $\Ym_{\text{miss}}$ son **independientes**.


## Distribución posterior

A partir de la información observada, se quiere obtener la distribución posterior de las cantidades desconocidas y faltantes:
$$
\begin{align*}
p(\tev,\SIG,\Ym_{\text{miss}}\mid\Ym_{\text{obs}},\Om) &\propto p(\Ym_{\text{obs}},\Om\mid \tev,\SIG,\Ym_{\text{miss}})\,\, p(\tev,\SIG,\Ym_{\text{miss}})\\
&= p(\Om\mid \tev,\SIG,\Ym_{\text{miss}},\Ym_{\text{obs}})\,\, p(\Ym_{\text{obs}}\mid \tev,\SIG,\Ym_{\text{miss}})\,\, p(\Ym_{\text{miss}}\mid\tev,\SIG)\,\, p(\tev,\SIG) \\
&= p(\Om\mid \Ym_{\text{obs}})\,\, p(\Ym_{\text{obs}}\mid \Ym_{\text{miss}}, \tev,\SIG)\,\, p(\Ym_{\text{miss}}\mid\tev,\SIG)\,\, p(\tev)\,\, p(\SIG) \\
&\propto  p(\Ym_{\text{obs}}\mid \Ym_{\text{miss}}, \tev,\SIG)\,\, p(\Ym_{\text{miss}}\mid\tev,\SIG)\,\, p(\tev)\,\,p(\SIG)\,.
\end{align*}
$$

Para obtener las distribuciones condicionales completas, se observa que
$$
p(\Ym\mid\tev,\SIG) = p(\Ym_{\text{obs}},\Ym_{\text{miss}}\mid\tev,\SIG) = p(\Ym_{\text{obs}}\mid \Ym_{\text{miss}}, \tev,\SIG)\,\, p(\Ym_{\text{miss}}\mid\tev,\SIG)
$$
y
$$
\begin{align*}
p(\Ym_{\text{miss}}\mid \Ym_{\text{obs}}, \tev,\SIG) 
&\propto p(\Ym_{\text{obs}},\Ym_{\text{miss}}\mid\tev,\SIG) \\
&= \prod_{i=1}^n p (\yv_{i,\text{obs}},\yv_{i,\text{miss}}\mid \tev,\SIG) \\
&\propto \prod_{i=1}^n p (\yv_{i,\text{miss}}\mid \yv_{i,\text{obs}}, \tev,\SIG)\,.
\end{align*}
$$

## Muestreador de Gibbs

A partir del estado actual $(\tev^{(b)},\SIG^{(b)},\Ym_{\text{miss}}^{(b)})$, se genera un nuevo estado $(\tev^{(b+1)},\SIG^{(b+1)},\Ym_{\text{miss}}^{(b+1)})$ como sigue:

1. Simular $\Ym_{\text{miss}}^{(b+1)} \sim p(\Ym_{\text{miss}}\mid \tev^{(b)}, \SIG_{\text{miss}}^{(b)}, \Ym_{\text{obs}})$.
2. Simular $\tev^{(b+1)} \sim p(\tev\mid \SIG^{(b)},   \Ym_{\text{miss}}^{(b+1)}, \Ym_{\text{obs}})$.
3. Simular $\SIG^{(b+1)} \sim p(\SIG\mid \tev^{(b+1)}, \Ym_{\text{miss}}^{(b+1)}, \Ym_{\text{obs}})$.


## Distribuciones condicionales completas

- La distribución condicional de $\yv_{i,[b]}\mid\yv_{i,[a]},\tev,\SIG$ es $\yv_{i,[b]}\mid\text{resto} \sim \textsf{N}(\tev_{b\mid a},\SIG_{b\mid a})$ donde
$$
\tev_{b\mid a} = \tev_{[b]} - \SIG_{[b,a]}\SIG_{[a,a]}^{-1}(\yv_{i,[a]} - \tev_{[a]})
\qquad\text{y}\qquad
\SIG_{b\mid a} = \SIG_{[b,b]} - \SIG_{[b,a]}\SIG_{[a,a]}^{-1}\SIG_{[a,b]}\,
$$
donde $b$ y $a$ almacenan los subíndices de $\yv_i$ que son $\text{miss}$ y $\text{obs}$, respectivamente.


- La distribución condicional completa de $\tev$ es $\tev\mid\text{resto}\sim\textsf{N}(\muv_n,\LAM_n)$, donde
$$
\muv_n = \left( \LAM_0^{-1} + n\SIG^{-1} \right)^{-1} \left( \LAM_0^{-1}\muv_0 + n\SIG^{-1}\bar{\boldsymbol{y}} \right)
\qquad\text{y}\qquad
\LAM_n = \left( \LAM_0^{-1} + n\SIG^{-1} \right)^{-1}\,.
$$

- La distribución condicional completa de $\SIG$ es $\SIG\mid\text{resto}\sim\textsf{WI}(\nu_n,\Sm_n^{-1})$, donde
$$
\nu_n = \nu_0 + n
\qquad\text{y}\qquad
\Sm_n = \Sm_0 + \sum_{i=1}^n (\boldsymbol{y}_i - \tev)(\boldsymbol{y}_i - \tev)^{\textsf{T}} = \Sm_0 + (n-1)\Sm + n(\bar{\boldsymbol y} - \tev)(\bar{\boldsymbol y} - \tev)^{\textsf{T}} \,.
$$


# Ejemplo: Diabetes

A una población de mujeres que tenían al menos 21 años, de herencia India Pima y que vivían cerca de Phoenix, Arizona, se les realizó una prueba de diabetes según los criterios de la Organización Mundial de la Salud. 

Los datos fueron recopilados por el Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales de EE. UU. 

- `glu` : concentración de glucosa plasmática en una prueba de tolerancia a la glucosa oral.
- `bp`  : presión arterial diastólica (mm Hg).
- `skin`: Grosor del pliegue cutáneo del tríceps (mm).
- `bmi` : índice de masa corporal (kg/m$^2$).

Datos disponibles en el paquete `MASS` de R.


## Datos

```{r}
# datos
# Y0 -> base de datos completa
# Y  -> base de datos con datos perdidos al azar 
# O  -> indicadora de datos observados
suppressMessages(suppressWarnings(library(MASS))) 
data(Pima.tr)
Y0 <- Pima.tr[,2:5]
(n <- dim(Y0)[1])
(p <- dim(Y0)[2])
```


```{r}
# datos perdidos al azar
Y <- Y0
set.seed(1)
O <- matrix(data = rbinom(n = n*p, size = 1, prob = 0.9), nrow = n, ncol = p)
Y[O == 0] <- NA
```


```{r}
# encabezado
head(Y)
```


```{r}
# vector de medias muestral
round(colMeans(Y, na.rm = T), 2)
```

```{r}
round(var(Y0, na.rm = T), 2)
```

```{r, fig.width=7, fig.height=7, fig.align='center'}
# visualización
par(mfrow = c(p,p), mar = 1.75*c(1,1,0.5,0.5), mgp = c(1.75,0.75,0))
for(j1 in 1:p) {
  for(j2 in 1:p) {
    if (j1 == j2) {
      hist(Y[,j1], col = "gray90", border = "gray90", main = "")
      mtext(colnames(Y)[j1], side=3, line = -0.1, cex = 0.7)
    }
    if (j1 != j2) {
      plot(x = Y[,j1], y = Y[,j2], xlab = "", ylab = "", pch = 16, cex = 0.7)
    }
  }
}
```

## Ajuste del modelo

```{r}
# hiperparámetros
# alternativa: usar información auxiliar de la encuesta nacional de salud
mu0 <- colMeans(Y, na.rm = T)
L0  <- var(Y, na.rm = T)
nu0 <- p + 2
S0  <- L0
```


```{r}
# valores iniciales
theta <- mu0 
Sigma <- S0
Yfull <- Y
for(j in 1:p)
  Yfull[is.na(Yfull[,j]), j] <- mean(Yfull[,j], na.rm = T)
```


```{r}
# número de muestras
B <- 10000
ncat <- floor(B/10)
```


```{r, eval = F}
# almacenamiento
THETA <- SIGMA <- YMISS <- LP <- NULL
```


```{r, echo = T, eval = F}
# cadena
iL0 <- solve(L0)
Lm0 <- solve(L0)%*%mu0
nun <- nu0 + n
for (b in 1:B) {
  # actualizar Y_miss
  for(i in 1:n) {
    miss <- O[i,] == 0
    if (any(miss)) {
      obs <- O[i,] == 1
      iSa <- solve(Sigma[obs,obs])
      m_j <- theta[miss] + Sigma[miss,obs]%*%iSa%*%t(Yfull[i,obs] - theta[obs])
      V_j <- Sigma[miss,miss] - Sigma[miss,obs]%*%iSa%*%Sigma[obs,miss]
      Yfull[i,miss] <- c(mvtnorm::rmvnorm(n = 1, mean = m_j, sigma = V_j))
    }
  }
  # actualizar estadísticos suficientes
  yb  <- colMeans(Yfull)
  SS  <- cov(Yfull)
  SSn <- S0 + (n-1)*SS
  # actualizar theta
  iSigma <- solve(Sigma)
  Ln     <- solve(iL0 + n*iSigma)
  theta  <- c(mvtnorm::rmvnorm(n = 1, mean = Ln%*%(Lm0 + n*(iSigma%*%yb)), sigma = Ln))
  # actualizar Sigma
  Sigma <- solve(rWishart::rWishart(n = 1, df = nun, Sigma = solve(SSn + n*((yb - theta)%*%t(yb - theta))))[,,1])     
  # log-verosimilitud
  LP[b] <- sum(apply(X = Yfull, MARGIN = 1, FUN = function(y) mvtnorm::dmvnorm(x = y, mean = theta, sigma = Sigma, log = T)))
  # almacenar
  THETA <- rbind(THETA, theta)
  SIGMA <- rbind(SIGMA, c(Sigma))
  YMISS <- rbind(YMISS, Yfull[O == 0])
  # progreso
  if (b%%ncat == 0) 
       cat(100*round(b/B, 1), "% completado ... \n", sep = "")
}
```


```{r, echo = F, eval = F}
save(THETA, SIGMA, YMISS, LP, file = "10-perdidos-samples.RData")
```


```{r, echo = F, eval = T}
load("C:/Users/User/Dropbox/UN/estadistica_bayesiana/10-perdidos-samples.RData")
```



## Convergencia

Cadena de la log-verosimilitud:

```{r, echo = FALSE, fig.width=8,fig.height=4, fig.align='center'}
# gráfico
par(mar = c(2.75,2.75,1.5,.5), mgp = c(1.7,0.7,0))
plot(x = 1:B, y = LP, type = "p", pch = ".", xlab = "Iteración", ylab = "Log-verosimilitud", main = "")
```

Coeficiente de Variación (\%) de Monte Carlo:

```{r, echo=F}
round(summary(c( 
     100*abs((apply(X = THETA, MARGIN = 2, FUN = sd)/sqrt(coda::effectiveSize(THETA)))/colMeans(THETA)),
     100*abs((apply(X = SIGMA, MARGIN = 2, FUN = sd)/sqrt(coda::effectiveSize(SIGMA)))/colMeans(SIGMA)))), 3)
```

## Inferencia

Inferencia sobre el vector de medias:

```{r}
colnames(THETA) <- paste0("theta", 1:p)
round(t(apply(X = THETA, MARGIN = 2, FUN = quantile, probs = c(0.025,0.5,0.975))), 2)
```


Inferencia sobre la matriz de correlación:

```{r}
COR <- array(data = NA, dim = c(p,p,B))
colnames(COR) <- rownames(COR) <- colnames(Y)
for(b in 1:B) {
  Sig <- matrix(data = SIGMA[b,], nrow = p, ncol = p)
  COR[,,b] <- Sig/sqrt(outer(diag(Sig), diag(Sig)))
}
round(apply(X = COR, MARGIN = c(1,2), FUN = mean), 2)
```

Inferencia sobre las correlaciones $\frac{\sigma_{i,j}}{\sigma_i\sigma_j}$ (izquierda) y los coeficientes de regresión de las predicciones $\boldsymbol{\beta}_{b\mid a}^\textsf{T} = \SIG_{[b,a]}\SIG_{[a,a]}^{-1}$ (derecha):

```{r, echo = F, fig.align='center', fig.width=7, fig.height=9}
# visualización
suppressMessages(suppressWarnings(library(sbgcop)))
par(mfcol=c(4,2), mar=c(1,2.75,1,1), mgp=c(1.75,0.75,0), oma=c(1.5,0,0,0))
plotci.sA(sA = COR)
plotci.sA(sA = sR.sC(sC = COR))
```

## Predicción

```{r, echo = F}
Y_true <- Y0
V <- matrix(data = 1:p, nrow=n, ncol = p, byrow = TRUE)
v_miss <- V[O == 0]
y_pred <- apply(X = YMISS, MARGIN = 2, FUN = mean)
y_true <- Y_true[O == 0]
```


```{r, echo = F, fig.align='center', fig.width=7, fig.height=7}
# visualización
par(mfrow=c(2,2), mar=c(3,3,1.5,1), mgp=c(1.75,0.75,0))
for (j in 1:p) {
  ran_j <- range(y_true[v_miss == j], y_pred[v_miss == j])
  mse_j <- mean((y_true[v_miss == j] - y_pred[v_miss == j])^2)
  cor_j <- cor(y_true[v_miss == j], y_pred[v_miss == j])
  plot(y_true[v_miss == j], y_pred[v_miss == j], pch = 16,
       xlim = ran_j, ylim = ran_j,
       xlab = paste("Verdadero", colnames(Y_true)[j]), 
       ylab = paste("Predicho", colnames(Y_true)[j]), 
       main = paste("MSE =", round(mse_j, 1), ", Cor = ", round(cor_j, 3)))
  abline(a = 0, b = 1, col = 2)
}
```


# Referencias {-}

```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Hoffcoverbook.jpg")
```


```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Gelmancoverbook.png")
```


```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("Reichcoverbook.jpg")
```
